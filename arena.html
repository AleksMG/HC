                        <!DOCTYPE html>
                        <html lang="en">
                        <head>
                            <meta charset="UTF-8">
                            <meta name="viewport" content="width=device-width, initial-scale=1.0">
              <style>
                body {
                  background-color: white; /* Ensure the iframe has a white background */
                }

                
              </style>
                        </head>
                        <body>
                            <!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline'; style-src 'self' 'unsafe-inline';">
    <title>üéÆ AI Arena v2.1.2 ‚Äî Professional Dual-Memory Learning Simulation</title>
    <style>
        :root {
            --bg: #0a0a15;
            --panel: #121225;
            --text: #e0e0ff;
            --primary: #00f2ff;
            --accent: #ff0066;
            --success: #00ff9d;
            --warning: #ffaa00;
            --danger: #ff4444;
            --border: #2a2a45;
            --purple: #aa88ff;
            --yellow: #ffdd44;
            --skill-hunt: #00ff9d;
            --skill-flee: #ff5577;
            --skill-combat: #ffaa00;
            --skill-explore: #00d4ff;
            --skill-avoid: #aa88ff;
        }
        
        @supports not (--css: variables) {
            body { background: #0a0a15; color: #e0e0ff; }
            .sidebar { background: #121225; }
            .panel { background: rgba(0,0,0,0.3); border-color: #2a2a45; }
        }
        
        * { margin: 0; padding: 0; box-sizing: border-box; font-family: 'Segoe UI', system-ui, sans-serif; }
        
        body { 
            background: var(--bg); 
            color: var(--text); 
            overflow: hidden;
            user-select: none;
        }
        
        .container { display: grid; grid-template-columns: 1fr 360px; height: 100vh; }
        
        #gameCanvas { 
            width: 100%; 
            height: 100%; 
            background: linear-gradient(135deg, #0a0a15 0%, #1a1a2e 100%);
            display: block;
            cursor: crosshair;
        }
        
        .sidebar {
            background: var(--panel);
            border-left: 1px solid var(--border);
            padding: 12px;
            overflow-y: auto;
            display: flex;
            flex-direction: column;
            gap: 10px;
        }
        
        .panel {
            background: rgba(0,0,0,0.3);
            border: 1px solid var(--border);
            border-radius: 12px;
            padding: 10px;
        }
        
        .panel-title {
            color: var(--primary);
            font-size: 0.8rem;
            font-weight: 700;
            margin-bottom: 8px;
            display: flex;
            align-items: center;
            gap: 5px;
        }
        
        .stat-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 5px;
        }
        
        .stat {
            background: rgba(0,0,0,0.2);
            padding: 5px 7px;
            border-radius: 6px;
            font-size: 0.65rem;
        }
        
        .stat-label { color: #888; display: block; margin-bottom: 1px; }
        .stat-value { color: var(--primary); font-weight: 700; font-family: 'Courier New', monospace; }
        .stat-value.good { color: var(--success); }
        .stat-value.bad { color: var(--danger); }
        .stat-value.warn { color: var(--warning); }
        
        .control-group { margin-bottom: 8px; }
        
        .control-label {
            display: flex;
            justify-content: space-between;
            align-items: center;
            font-size: 0.7rem;
            margin-bottom: 3px;
            color: #aaa;
        }
        
        input[type="range"] {
            width: 100%;
            height: 4px;
            background: var(--border);
            border-radius: 2px;
            outline: none;
            appearance: none;
            -webkit-appearance: none;
        }
        
        input[type="range"]::-webkit-slider-thumb {
            -webkit-appearance: none;
            width: 13px;
            height: 13px;
            background: var(--primary);
            border-radius: 50%;
            cursor: pointer;
        }
        
        .btn-group { display: grid; grid-template-columns: 1fr 1fr; gap: 5px; margin-top: 6px; }
        
        button {
            padding: 7px;
            border: none;
            border-radius: 6px;
            font-weight: 700;
            cursor: pointer;
            font-size: 0.7rem;
            transition: all 0.2s;
            text-transform: uppercase;
        }
        
        button:focus, input:focus { 
            outline: 2px solid var(--primary, #00f2ff); 
            outline-offset: 2px; 
        }
        
        .btn-primary { background: var(--primary); color: #000; }
        .btn-primary:hover { background: #fff; transform: translateY(-1px); }
        .btn-danger { background: var(--danger); color: #fff; }
        .btn-danger:hover { background: #ff6666; }
        .btn-success { background: var(--success); color: #000; }
        .btn-success:hover { background: #66ffcc; }
        .btn-secondary { background: var(--border); color: var(--text); }
        .btn-secondary:hover { background: #3a3a55; }
        .btn-toggle { background: var(--border); color: var(--text); }
        .btn-toggle.active { background: var(--accent); color: #fff; }
        
        .log {
            background: #000;
            border: 1px solid var(--border);
            border-radius: 8px;
            padding: 7px;
            height: 100px;
            overflow-y: auto;
            font-size: 0.6rem;
            font-family: 'Courier New', monospace;
            word-break: break-word;
            white-space: pre-wrap;
            max-width: 100%;
        }
        
        .log-entry { margin-bottom: 2px; padding-bottom: 2px; border-bottom: 1px solid #111; }
        .log-entry.info { color: var(--primary); }
        .log-entry.success { color: var(--success); }
        .log-entry.warn { color: var(--warning); }
        .log-entry.error { color: var(--danger); }
        
        .progress-bar {
            height: 5px;
            background: rgba(0,0,0,0.3);
            border-radius: 3px;
            overflow: hidden;
            margin-top: 4px;
        }
        
        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, var(--primary), var(--success));
            transition: width 0.3s;
        }
        
        .agent-legend {
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: 4px;
            margin-top: 6px;
        }
        
        .legend-item {
            display: flex;
            align-items: center;
            gap: 4px;
            font-size: 0.6rem;
        }
        
        .legend-color {
            width: 9px;
            height: 9px;
            border-radius: 2px;
        }
        
        .toggle {
            display: flex;
            align-items: center;
            gap: 5px;
            font-size: 0.7rem;
            margin-bottom: 5px;
        }
        
        .toggle input { accent-color: var(--primary); }
        
        .header {
            grid-column: 1 / -1;
            background: var(--panel);
            border-bottom: 1px solid var(--border);
            padding: 10px 12px;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        
        .header h1 {
            font-size: 0.95rem;
            color: var(--primary);
            display: flex;
            align-items: center;
            gap: 7px;
        }
        
        .fps-counter {
            font-family: 'Courier New', monospace;
            color: var(--success);
            font-weight: 700;
            font-size: 0.75rem;
        }
        
        ::-webkit-scrollbar { width: 4px; }
        ::-webkit-scrollbar-track { background: var(--bg); }
        ::-webkit-scrollbar-thumb { background: var(--border); border-radius: 2px; }
        
        .version-badge {
            background: var(--accent);
            color: #fff;
            padding: 1px 5px;
            border-radius: 3px;
            font-size: 0.5rem;
            margin-left: 5px;
        }
        
        .mode-badge {
            display: inline-flex;
            align-items: center;
            gap: 3px;
            padding: 1px 5px;
            border-radius: 8px;
            font-size: 0.55rem;
            margin-left: 6px;
        }
        .mode-hunt { background: rgba(0,255,157,0.2); color: var(--skill-hunt); }
        .mode-flee { background: rgba(255,85,119,0.2); color: var(--skill-flee); }
        .mode-explore { background: rgba(0,212,255,0.2); color: var(--skill-explore); }
        .mode-combat { background: rgba(255,170,0,0.2); color: var(--skill-combat); }
        .mode-avoid { background: rgba(170,136,255,0.2); color: var(--skill-avoid); }
        
        .debug-panel {
            background: rgba(0,0,0,0.4);
            border: 1px solid var(--border);
            border-radius: 8px;
            padding: 8px;
            font-size: 0.6rem;
            display: none;
        }
        .debug-panel.active { display: block; }
        .debug-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 3px 6px;
        }
        .debug-item { display: flex; justify-content: space-between; }
        .debug-label { color: #888; }
        .debug-value { color: var(--primary); font-weight: 600; }
        
        .agent-card {
            display: flex;
            flex-direction: column;
            gap: 5px;
            padding: 7px;
            background: rgba(0,0,0,0.2);
            border-radius: 8px;
            margin-bottom: 7px;
        }
        .agent-card.blue { border-left: 3px solid var(--primary); }
        .agent-card.red { border-left: 3px solid var(--accent); }
        .agent-header {
            display: flex;
            align-items: center;
            gap: 5px;
            font-size: 0.7rem;
            font-weight: 600;
        }
        .health-bar {
            height: 4px;
            background: rgba(0,0,0,0.3);
            border-radius: 2px;
            overflow: hidden;
        }
        .health-fill {
            height: 100%;
            background: linear-gradient(90deg, var(--success), var(--primary));
            transition: width 0.2s;
        }
        .health-fill.low { background: linear-gradient(90deg, var(--danger), var(--warning)); }
        .agent-stats {
            display: flex;
            justify-content: space-between;
            font-size: 0.6rem;
            color: #aaa;
        }
        .agent-stats b { color: var(--text); }
        
        .skills-display {
            display: grid;
            grid-template-columns: repeat(5, 1fr);
            gap: 3px;
            margin-top: 5px;
        }
        .skill-item {
            text-align: center;
            font-size: 0.55rem;
        }
        .skill-bar {
            height: 3px;
            background: rgba(0,0,0,0.3);
            border-radius: 1px;
            margin-top: 2px;
            overflow: hidden;
        }
        .skill-fill {
            height: 100%;
            transition: width 0.3s;
        }
        .skill-hunt .skill-fill { background: var(--skill-hunt); }
        .skill-flee .skill-fill { background: var(--skill-flee); }
        .skill-combat .skill-fill { background: var(--skill-combat); }
        .skill-explore .skill-fill { background: var(--skill-explore); }
        .skill-avoid .skill-fill { background: var(--skill-avoid); }
        
        .confidence-meter {
            display: flex;
            align-items: center;
            gap: 4px;
            margin-top: 4px;
            font-size: 0.6rem;
        }
        .confidence-bar {
            flex: 1;
            height: 4px;
            background: rgba(0,0,0,0.3);
            border-radius: 2px;
            overflow: hidden;
        }
        .confidence-fill {
            height: 100%;
            background: linear-gradient(90deg, var(--danger), var(--warning), var(--success));
            transition: width 0.2s;
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>üéÆ AI ARENA <span class="version-badge">v2.1.2 PRO</span></h1>
        <div class="fps-counter" id="fpsCounter">FPS: 60</div>
    </div>
    
    <div class="container">
        <canvas id="gameCanvas"></canvas>
        
        <noscript>
            <div style="grid-column:1/-1;padding:15px;background:var(--danger);color:#fff;text-align:center;font-size:0.7rem;">‚ö†Ô∏è –î–ª—è —Ä–∞–±–æ—Ç—ã AI Arena —Ç—Ä–µ–±—É–µ—Ç—Å—è JavaScript</div>
        </noscript>
        
        <div class="sidebar">
            <!-- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–≥–µ–Ω—Ç–æ–≤ -->
            <div class="panel">
                <div class="panel-title">üë• –ê–ì–ï–ù–¢–´</div>
                <div class="agent-card blue">
                    <div class="agent-header">
                        <span>üîµ BLUE</span>
                        <span class="mode-badge mode-explore" id="blue-mode">EXPLORE</span>
                    </div>
                    <div class="health-bar"><div class="health-fill" id="blue-health" style="width:100%"></div></div>
                    <div class="agent-stats">
                        <span>Reward: <b id="blue-reward">0.00</b></span>
                        <span>Wins: <b id="blue-wins">0</b></span>
                        <span>Conf: <b id="blue-conf">0.50</b></span>
                    </div>
                    <div class="skills-display" id="blue-skills">
                        <div class="skill-item skill-hunt"><div class="skill-bar"><div class="skill-fill" style="width:30%"></div></div><div>H</div></div>
                        <div class="skill-item skill-flee"><div class="skill-bar"><div class="skill-fill" style="width:40%"></div></div><div>F</div></div>
                        <div class="skill-item skill-combat"><div class="skill-bar"><div class="skill-fill" style="width:20%"></div></div><div>C</div></div>
                        <div class="skill-item skill-explore"><div class="skill-bar"><div class="skill-fill" style="width:50%"></div></div><div>E</div></div>
                        <div class="skill-item skill-avoid"><div class="skill-bar"><div class="skill-fill" style="width:60%"></div></div><div>A</div></div>
                    </div>
                </div>
                <div class="agent-card red">
                    <div class="agent-header">
                        <span>üî¥ RED</span>
                        <span class="mode-badge mode-explore" id="red-mode">EXPLORE</span>
                    </div>
                    <div class="health-bar"><div class="health-fill" id="red-health" style="width:100%"></div></div>
                    <div class="agent-stats">
                        <span>Reward: <b id="red-reward">0.00</b></span>
                        <span>Wins: <b id="red-wins">0</b></span>
                        <span>Conf: <b id="red-conf">0.50</b></span>
                    </div>
                    <div class="skills-display" id="red-skills">
                        <div class="skill-item skill-hunt"><div class="skill-bar"><div class="skill-fill" style="width:30%"></div></div><div>H</div></div>
                        <div class="skill-item skill-flee"><div class="skill-bar"><div class="skill-fill" style="width:40%"></div></div><div>F</div></div>
                        <div class="skill-item skill-combat"><div class="skill-bar"><div class="skill-fill" style="width:20%"></div></div><div>C</div></div>
                        <div class="skill-item skill-explore"><div class="skill-bar"><div class="skill-fill" style="width:50%"></div></div><div>E</div></div>
                        <div class="skill-item skill-avoid"><div class="skill-bar"><div class="skill-fill" style="width:60%"></div></div><div>A</div></div>
                    </div>
                </div>
            </div>

            <!-- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏–º—É–ª—è—Ü–∏–∏ -->
            <div class="panel">
                <div class="panel-title">üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê</div>
                <div class="stat-grid">
                    <div class="stat"><span class="stat-label">–≠–ø–∏–∑–æ–¥</span><span class="stat-value" id="episodeStat">0</span></div>
                    <div class="stat"><span class="stat-label">–®–∞–≥</span><span class="stat-value" id="stepStat">0</span></div>
                    <div class="stat"><span class="stat-label">–¢–æ—á–∫–∏</span><span class="stat-value" id="dotsStat">50</span></div>
                    <div class="stat"><span class="stat-label">–ü—Ä–µ–ø—è—Ç—Å—Ç–≤–∏—è</span><span class="stat-value" id="obstaclesStat">12</span></div>
                    <div class="stat"><span class="stat-label">–°—Ä. —Ñ–∏—Ç–Ω–µ—Å</span><span class="stat-value good" id="fitnessStat">0</span></div>
                    <div class="stat"><span class="stat-label">–õ—É—á—à–∏–π</span><span class="stat-value good" id="bestFitnessStat">0</span></div>
                </div>
                <div class="progress-bar"><div class="progress-fill" id="episodeProgress" style="width: 0%"></div></div>
            </div>

            <!-- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—É—á–µ–Ω–∏—è -->
            <div class="panel">
                <div class="panel-title">üß† –û–ë–£–ß–ï–ù–ò–ï</div>
                <div class="control-group">
                    <div class="control-label"><span>Learning Rate</span><span id="learningRateValue">0.005</span></div>
                    <input type="range" id="learningRate" min="0.001" max="0.05" step="0.001" value="0.005">
                </div>
                <div class="control-group">
                    <div class="control-label"><span>Hebbian Rate</span><span id="hebbianRateValue">0.002</span></div>
                    <input type="range" id="hebbianRate" min="0.0005" max="0.01" step="0.0005" value="0.002">
                </div>
                <div class="control-group">
                    <div class="control-label"><span>Mutation</span><span id="mutationRateValue">0.1</span></div>
                    <input type="range" id="mutationRate" min="0.05" max="0.3" step="0.01" value="0.1">
                </div>
                <div class="control-group">
                    <div class="control-label"><span>Skill Growth</span><span id="skillGrowthValue">0.04</span></div>
                    <input type="range" id="skillGrowth" min="0.01" max="0.1" step="0.01" value="0.04">
                </div>
                <div class="toggle"><input type="checkbox" id="enableTraining" checked><label for="enableTraining">Hebbian Learning</label></div>
                <div class="toggle"><input type="checkbox" id="enableEvolution" checked><label for="enableEvolution">Weight Mutation</label></div>
                <div class="toggle"><input type="checkbox" id="enableSkillEvolution" checked><label for="enableSkillEvolution">Skill Evolution</label></div>
                <div class="toggle"><input type="checkbox" id="enableFighting" checked><label for="enableFighting">–ë–æ–∏ –º–µ–∂–¥—É –∞–≥–µ–Ω—Ç–∞–º–∏</label></div>
                <div class="toggle"><input type="checkbox" id="enableVisualization"><label for="enableVisualization">–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ–π—Ä–æ–Ω–æ–≤</label></div>
            </div>

            <!-- –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ -->
            <div class="panel">
                <div class="panel-title">üéÆ –£–ü–†–ê–í–õ–ï–ù–ò–ï</div>
                <div class="btn-group">
                    <button class="btn-primary" id="btnStart">‚ñ∂ –°—Ç–∞—Ä—Ç</button>
                    <button class="btn-danger" id="btnReset">üîÑ –°–±—Ä–æ—Å</button>
                    <button class="btn-success" id="btnSave">üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å</button>
                    <button class="btn-secondary" id="btnLoad">üìÇ –ó–∞–≥—Ä—É–∑–∏—Ç—å</button>
                </div>
                <div class="btn-group" style="margin-top: 5px;">
                    <button class="btn-toggle" id="btnDebug">üîç Debug</button>
                    <button class="btn-toggle" id="btnVision">üëÅÔ∏è Vision</button>
                    <button class="btn-secondary" id="btnExport">üì§ –≠–∫—Å–ø–æ—Ä—Ç</button>
                    <button class="btn-secondary" id="btnImport">üì• –ò–º–ø–æ—Ä—Ç</button>
                </div>
                <input type="file" id="fileImport" accept=".json" style="display:none">
            </div>

            <!-- –õ–µ–≥–µ–Ω–¥–∞ -->
            <div class="panel">
                <div class="panel-title">üé® –õ–ï–ì–ï–ù–î–ê</div>
                <div class="agent-legend">
                    <div class="legend-item"><div class="legend-color" style="background:#00d4ff"></div><span>–ê–≥–µ–Ω—Ç</span></div>
                    <div class="legend-item"><div class="legend-color" style="background:#00ff9d"></div><span>–¢–æ—á–∫–∞ (5)</span></div>
                    <div class="legend-item"><div class="legend-color" style="background:#ff66cc"></div><span>Scared (8)</span></div>
                    <div class="legend-item"><div class="legend-color" style="background:#ffaa00"></div><span>Rare (20)</span></div>
                    <div class="legend-item"><div class="legend-color" style="background:#4a4a7a"></div><span>–ü—Ä–µ–ø—è—Ç—Å—Ç–≤–∏–µ</span></div>
                    <div class="legend-item"><div class="legend-color" style="background:linear-gradient(90deg,var(--skill-hunt),var(--skill-combat))"></div><span>–ù–∞–≤—ã–∫–∏</span></div>
                </div>
            </div>

            <!-- –õ–æ–≥ -->
            <div class="panel">
                <div class="panel-title">üìù –õ–û–ì</div>
                <div class="log" id="eventLog"></div>
            </div>

            <!-- Debug –ø–∞–Ω–µ–ª—å -->
            <div class="debug-panel" id="debugPanel">
                <div style="margin-bottom:5px;font-weight:600;color:var(--primary)">üîç INSPECTOR</div>
                <div class="debug-grid" id="debugGrid">
                    <div class="debug-item"><span class="debug-label">Mode</span><span class="debug-value" id="dbgMode">‚Äî</span></div>
                    <div class="debug-item"><span class="debug-label">Target</span><span class="debug-value" id="dbgTarget">‚Äî</span></div>
                    <div class="debug-item"><span class="debug-label">Speed</span><span class="debug-value" id="dbgSpeed">‚Äî</span></div>
                    <div class="debug-item"><span class="debug-label">Aggro</span><span class="debug-value" id="dbgAggro">‚Äî</span></div>
                    <div class="debug-item"><span class="debug-label">Memory</span><span class="debug-value" id="dbgMemory">‚Äî</span></div>
                    <div class="debug-item"><span class="debug-label">Neurons</span><span class="debug-value" id="dbgNeurons">‚Äî</span></div>
                    <div class="debug-item"><span class="debug-label">Reward</span><span class="debug-value" id="dbgReward">‚Äî</span></div>
                    <div class="debug-item"><span class="debug-label">Stuck</span><span class="debug-value" id="dbgStuck">‚Äî</span></div>
                    <div class="debug-item"><span class="debug-label">Confidence</span><span class="debug-value" id="dbgConf">‚Äî</span></div>
                    <div class="debug-item"><span class="debug-label">Pred.Error</span><span class="debug-value" id="dbgPredErr">‚Äî</span></div>
                </div>
                <div class="confidence-meter">
                    <span>Confidence:</span>
                    <div class="confidence-bar"><div class="confidence-fill" id="dbgConfBar" style="width:50%"></div></div>
                    <span id="dbgConfVal">0.50</span>
                </div>
            </div>
        </div>
    </div>

<script>
/**
 * ============================================================================
 * AI ARENA v2.1.2 ‚Äî PROFESSIONAL DUAL-MEMORY LEARNING SIMULATION
 * ============================================================================
 * üîß –¢–û–ß–ï–ß–ù–´–ï –ü–ê–¢–ß–ò (–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –Ω–∞ 100%):
 * 
 * üî¥ FIX #1: –ê–≥–µ–Ω—Ç—ã —Å—Ç–æ—è—Ç –Ω–∞ –º–µ—Å—Ç–µ —É —Å—Ç–µ–Ω
 *    - –í move() –¥–æ–±–∞–≤–ª–µ–Ω guaranteed minimum velocity
 *    - Anti-cancellation: –µ—Å–ª–∏ –≤–µ–∫—Ç–æ—Ä–∞ –≥–∞—Å—è—Ç –¥—Ä—É–≥ –¥—Ä—É–≥–∞ ‚Üí —á–∏—Å—Ç—ã–π desired
 * 
 * üî¥ FIX #2: –¢–æ—á–∫–∏ –Ω–µ —Å–æ–±–∏—Ä–∞—é—Ç—Å—è
 *    - –†–∞–¥–∏—É—Å —Å–±–æ—Ä–∞ —É–≤–µ–ª–∏—á–µ–Ω: 12‚Üí18
 *    - Force collection fallback –µ—Å–ª–∏ —Ç–æ—á–∫–∞ <10px
 * 
 * üî¥ FIX #3: –ù–µ–π—Ä–æ—Å–µ—Ç—å –Ω–µ –≤–ª–∏—è–µ—Ç –Ω–∞ –ø–æ–≤–µ–¥–µ–Ω–∏–µ (–ö–õ–Æ–ß–ï–í–û–ô)
 *    - –í calculateTarget() outputs[9-12] –º–æ–¥—É–ª–∏—Ä—É—é—Ç –≤—ã–±–æ—Ä —Ü–µ–ª–∏
 *    - –í move() network outputs –º–æ–¥—É–ª–∏—Ä—É—é—Ç final direction
 * 
 * üî¥ FIX #4: Hebbian learning —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º–∏ –≤—Ö–æ–¥–∞–º–∏
 *    - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Math.abs() + sign correlation (—É–∂–µ –≤ –≤–∞—à–µ–º –∫–æ–¥–µ)
 * 
 * üî¥ FIX #5: Canvas –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã (—É–∂–µ –≤ –≤–∞—à–µ–º –∫–æ–¥–µ)
 * 
 * üî¥ FIX #6: Invalid target –∫—Ä–∞—à–∏—Ç –∞–≥–µ–Ω—Ç–∞ (—É–∂–µ –≤ –≤–∞—à–µ–º –∫–æ–¥–µ)
 * 
 * ‚úÖ –í–°–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê v2.1.2 –°–û–•–†–ê–ù–ï–ù–ê:
 * - Neural Network 24‚Üí48‚Üí36‚Üí16 + RNN(16)
 * - Dual-Memory (permanent + predictive)
 * - Behavior Arbiter —Å 5 —Ä–µ–∂–∏–º–∞–º–∏
 * - Skill gating —Å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è–º–∏
 * - Muscle Memory (Float32Array)
 * - –í—Å–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏, UI, —ç–∫—Å–ø–æ—Ä—Ç/–∏–º–ø–æ—Ä—Ç
 * ============================================================================
 */

// ============================================================================
// 1. UTILITIES
// ============================================================================

const Utils = {
    clamp: (v, min, max) => Math.max(min, Math.min(max, v)),
    lerp: (a, b, t) => a + (b - a) * t,
    dist: (a, b) => Math.hypot(a.x - b.x, a.y - b.y),
    normalize: (x, y) => { const l = Math.hypot(x, y) || 1; return { x: x/l, y: y/l }; },
    tanh: x => { const e = Math.exp(2*x); return (e-1)/(e+1); },
    sigmoid: x => 1/(1+Math.exp(-x)),
    leakyRelu: (x, Œ±=0.01) => x > 0 ? x : Œ±*x,
    argmax: arr => arr.reduce((mi, v, i, a) => v > a[mi] ? i : mi, 0),
    rand: (min, max) => Math.random() * (max - min) + min,
    randInt: (min, max) => Math.floor(Math.random() * (max - min + 1)) + min,
    safeNumber: (val, fallback = 0) => (typeof val === 'number' && isFinite(val)) ? val : fallback,
};

class SeededRNG {
    constructor(seed) {
        this.seed = seed.split('').reduce((a,c) => a + c.charCodeAt(0), 0) || 12345;
    }
    next() {
        this.seed = (this.seed * 9301 + 49297) % 233280;
        return this.seed / 233280;
    }
}

// ============================================================================
// 2. NEURAL NETWORK 24‚Üí48‚Üí36‚Üí16 + RNN MEMORY
// ============================================================================

class NeuralNetwork {
    constructor(config) {
        this.inputDim = config.inputDim || 24;
        this.hidden1 = config.hidden1 || 48;
        this.hidden2 = config.hidden2 || 36;
        this.outputDim = config.outputDim || 16;
        this.memoryDim = config.memoryDim || 16;
        this.seed = config.seed || 'default';
        this.rng = new SeededRNG(this.seed);
        
        this.W1 = this._randMat(this.inputDim + this.memoryDim, this.hidden1, 0.3);
        this.W2 = this._randMat(this.hidden1, this.hidden2, 0.2);
        this.W3 = this._randMat(this.hidden2, this.outputDim, 0.1);
        
        this.memory = new Array(this.memoryDim).fill(0);
        this.lr = config.lr || 0.005;
        this.hebbianRate = config.hebbianRate || 0.002;
        this.activeNeurons = [];
    }
    
    _randMat(rows, cols, scale) {
        const m = [];
        for(let i=0; i<rows; i++) {
            const row = [];
            for(let j=0; j<cols; j++) row.push(Utils.safeNumber((this.rng.next()*2-1)*scale, 0));
            m.push(row);
        }
        return m;
    }
    
    _matMul(vec, mat) {
        const out = [];
        for(let i=0; i<mat[0].length; i++) {
            let sum = 0;
            for(let j=0; j<vec.length; j++) sum += Utils.safeNumber(vec[j], 0) * Utils.safeNumber(mat[j][i], 0);
            out.push(Utils.tanh(sum));
        }
        return out;
    }
    
    forward(inputs) {
        if (!inputs || inputs.length !== this.inputDim) {
            inputs = new Array(this.inputDim).fill(0);
        }
        
        this.lastInputs = inputs.slice();
        const combined = [...inputs, ...this.memory];
        
        let h1 = this._matMul(combined, this.W1);
        let h2 = this._matMul(h1, this.W2);
        let output = this._matMul(h2, this.W3);
        
        this.memory = h2.slice(0, this.memoryDim);
        
        this.activeNeurons = [...h1, ...h2, ...output]
            .map((v,i) => ({i, v: Utils.safeNumber(v, 0)}))
            .sort((a,b) => Math.abs(b.v) - Math.abs(a.v))
            .slice(0, 5)
            .map(n => n.i);
        
        return { 
            output: output.map(v => Utils.safeNumber(v, 0)), 
            memory: this.memory.slice(), 
            activeNeurons: this.activeNeurons 
        };
    }
    
    // üîß FIX #4: Hebbian learning with absolute values + sign correlation
    hebbianUpdate(inputs, outputs, reward) {
        if (reward <= 0) return;
        for(let i=0; i<Math.min(inputs.length, this.W1.length); i++) {
            for(let o=0; o<Math.min(outputs.length, this.W1[0].length); o++) {
                // üîß –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–±—Å–æ–ª—é—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏ –∑–Ω–∞–∫
                const inputActive = Math.abs(Utils.safeNumber(inputs[i], 0)) > 0.4;
                const outputActive = Math.abs(Utils.safeNumber(outputs[o], 0)) > 0.4;
                
                if (inputActive && outputActive) {
                    // –£—Å–∏–ª–∏–≤–∞—Ç—å –µ—Å–ª–∏ –∑–Ω–∞–∫–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç
                    const sign = Math.sign(inputs[i]) * Math.sign(outputs[o]);
                    this.W1[i][o] += this.hebbianRate * reward * sign;
                    this.W1[i][o] = Utils.clamp(this.W1[i][o], -1, 1);
                }
            }
        }
    }
    
    mutate(rate = 0.1, strength = 0.1) {
        let mutations = 0;
        const mutateMat = (mat) => {
            for(let i=0; i<mat.length; i++) {
                for(let j=0; j<mat[i].length; j++) {
                    if (this.rng.next() < rate) {
                        mat[i][j] += (this.rng.next()*2-1)*strength;
                        mat[i][j] = Utils.clamp(mat[i][j], -2, 2);
                        mutations++;
                    }
                }
            }
        };
        mutateMat(this.W1); mutateMat(this.W2); mutateMat(this.W3);
        return mutations;
    }
    
    clone() {
        const clone = new NeuralNetwork({
            inputDim: this.inputDim, hidden1: this.hidden1, hidden2: this.hidden2,
            outputDim: this.outputDim, memoryDim: this.memoryDim,
            seed: this.seed + '_clone_' + Date.now(), lr: this.lr, hebbianRate: this.hebbianRate
        });
        clone.W1 = this.W1.map(r => r.slice());
        clone.W2 = this.W2.map(r => r.slice());
        clone.W3 = this.W3.map(r => r.slice());
        clone.memory = this.memory.slice();
        return clone;
    }
    
    toJSON() {
        return {
            config: { 
                inputDim: this.inputDim, hidden1: this.hidden1, hidden2: this.hidden2,
                outputDim: this.outputDim, memoryDim: this.memoryDim,
                seed: this.seed, lr: this.lr, hebbianRate: this.hebbianRate 
            },
            W1: this.W1.map(r=>r.slice()), 
            W2: this.W2.map(r=>r.slice()), 
            W3: this.W3.map(r=>r.slice()),
            memory: this.memory.slice()
        };
    }
    
    static fromJSON(data) {
        if (!data || !data.config) {
            return new NeuralNetwork({});
        }
        const nn = new NeuralNetwork(data.config);
        try {
            nn.W1 = (data.W1 || []).map(r => (r || []).slice());
            nn.W2 = (data.W2 || []).map(r => (r || []).slice());
            nn.W3 = (data.W3 || []).map(r => (r || []).slice());
            nn.memory = (data.memory || []).slice();
        } catch(e) {
            console.warn('NeuralNetwork.fromJSON: error loading weights', e);
        }
        return nn;
    }
}

// ============================================================================
// 3. BEHAVIOR ARBITER WITH SKILL GATING + NEURAL MODULATION
// ============================================================================

class BehaviorArbiter {
    constructor() {
        this.modes = ['hunt', 'flee', 'explore', 'combat', 'avoid'];
    }
    
    decode(outputs) {
        return {
            hunt: Utils.clamp(Utils.safeNumber(outputs[0], 0), 0, 1),
            flee: Utils.clamp(Utils.safeNumber(outputs[1], 0), 0, 1),
            explore: Utils.clamp(Utils.safeNumber(outputs[2], 0), 0, 1),
            combat: Utils.clamp(Utils.safeNumber(outputs[3], 0), 0, 1),
            avoid: Utils.clamp(Utils.safeNumber(outputs[4], 0), 0, 1),
            speed: Utils.clamp(Utils.safeNumber(outputs[5], 0), 0, 1),
            curiosity: Utils.clamp(Utils.safeNumber(outputs[6], 0), 0, 1),
            aggression: Utils.clamp(Utils.safeNumber(outputs[7], 0), 0, 1),
            memoryWeight: Utils.clamp(Utils.safeNumber(outputs[8], 0), 0, 1),
        };
    }
    
    select(behaviors, context, skills = null) {
        if (context.enemyDistance < 5 && context.health > 0.3) {
            behaviors.combat *= 1.5;
        } else {
            behaviors.combat *= 0.1;
        }
        
        if (context.wallDistance < 2.5) {
            behaviors.avoid *= 2.0;
        } else {
            behaviors.avoid *= 0.3;
        }
        
        if (context.health < 0.25) {
            behaviors.flee *= 2.0;
            behaviors.combat *= 0.2;
        }
        
        if (skills) {
            const skillMap = {
                'hunt': skills.hunting ?? 0.5,
                'flee': skills.fleeing ?? 0.5,
                'explore': skills.exploring ?? 0.5,
                'combat': skills.combat ?? 0.5,
                'avoid': skills.avoiding ?? 0.5
            };
            for (const mode of this.modes) {
                const skill = skillMap[mode];
                behaviors[mode] *= (0.6 + skill * 0.8);
            }
        }
        
        const scores = this.modes.map(m => behaviors[m]);
        const mode = this.modes[Utils.argmax(scores)];
        
        return { mode, behaviors };
    }
    
    // üîß FIX #3: Neural network outputs now MODULATE target calculation
    calculateTarget(mode, behaviors, agent, world, networkOutputs = null) {
        const { points, enemies, walls } = world;
        
        switch(mode) {
            case 'hunt': {
                let targets = points.filter(p => !p.collected);
                
                // Remembered - –û–ö (—ç—Ç–æ –±—ã–ª–∞ —Ä–µ–∞–ª—å–Ω–∞—è —Ç–æ—á–∫–∞)
                if (agent.permanent?.memory?.lastFoodPos && behaviors.memoryWeight > 0.5) {
                    const memAge = world.step - (agent.permanent.memory.lastFoodStep || 0);
                    if (memAge < 100) {
                        targets = [...targets, {
                            x: agent.permanent.memory.lastFoodPos.x, 
                            y: agent.permanent.memory.lastFoodPos.y, 
                            value: 1,
                            type: 'remembered'
                        }];
                    }
                }
                
                // üîß FIX: Neural network outputs modulate target selection
                // outputs[9]=direction bias X, outputs[10]=direction bias Y, outputs[11]=target priority
                if (networkOutputs && networkOutputs.length >= 12) {
                    const dirBiasX = Utils.tanh(networkOutputs[9] || 0) * 30;
                    const dirBiasY = Utils.tanh(networkOutputs[10] || 0) * 30;
                    const priorityMod = (networkOutputs[11] || 0.5) * 2; // 0..2
                    
                    // Apply bias to all targets
                    targets.forEach(t => {
                        t.x += dirBiasX * priorityMod * 0.15;
                        t.y += dirBiasY * priorityMod * 0.15;
                    });
                    
                    // Sort with network influence
                    targets.sort((a,b) => {
                        const distA = Utils.dist(agent, a) - (priorityMod * 10);
                        const distB = Utils.dist(agent, b) - (priorityMod * 10);
                        return distA - distB;
                    });
                } else {
                    targets.sort((a,b) => Utils.dist(agent, a) - Utils.dist(agent, b));
                }
                
                return targets[0] || {
                    x: Utils.clamp(agent.x + Utils.rand(-100,100), 25, 795), 
                    y: Utils.clamp(agent.y + Utils.rand(-75,75), 25, 575)
                };
            }
            case 'flee': {
                const threats = enemies.filter(e => e.id !== agent.id && e.alive);
                if (!threats.length) return {
                    x: Utils.clamp(agent.x + Utils.rand(-80,80), 25, 795), 
                    y: Utils.clamp(agent.y + Utils.rand(-60,60), 25, 575)
                };
                let threat = threats.reduce((n, e) => Utils.dist(agent, e) < Utils.dist(agent, n) ? e : n);
                if (agent.predictive?.predictedEnemy && agent.predictive?.confidence > 0.7) {
                    threat = {...threat, ...agent.predictive.predictedEnemy};
                }
                const away = Utils.normalize(agent.x - threat.x, agent.y - threat.y);
                
                // üîß Network can modulate flee direction
                if (networkOutputs && networkOutputs.length >= 12) {
                    const fleeBias = Utils.tanh(networkOutputs[9] || 0) * 0.3;
                    return {
                        x: agent.x + (away.x + fleeBias) * 40,
                        y: agent.y + (away.y + (networkOutputs[10] || 0) * 0.3) * 40
                    };
                }
                
                return {x: agent.x + away.x * 40, y: agent.y + away.y * 40};
            }
            case 'explore': {
                if (behaviors.curiosity > 0.7 && agent.permanent?.memory?.unvisited?.length) {
                    return agent.permanent.memory.unvisited[
                        Math.floor(Utils.rand(0, agent.permanent.memory.unvisited.length-1))
                    ];
                }
                
                // üîß Network modulates exploration direction
                if (networkOutputs && networkOutputs.length >= 12) {
                    return {
                        x: Utils.clamp(agent.x + Utils.tanh(networkOutputs[9]||0) * 120, 25, 795),
                        y: Utils.clamp(agent.y + Utils.tanh(networkOutputs[10]||0) * 90, 25, 575)
                    };
                }
                
                return {
                    x: Utils.clamp(agent.x + Utils.rand(-120,120), 25, 795),
                    y: Utils.clamp(agent.y + Utils.rand(-90,90), 25, 575)
                };
            }
            case 'combat': {
                const targets = enemies.filter(e => e.id !== agent.id && e.alive);
                if (!targets.length) return {x: agent.x, y: agent.y};
                let target = targets.reduce((n, e) => Utils.dist(agent, e) < Utils.dist(agent, n) ? e : n);
                if (agent.predictive?.predictedEnemy && agent.predictive?.confidence > 0.65) {
                    target = {...target, ...agent.predictive.predictedEnemy};
                }
                return target;
            }
            case 'avoid': {
                const nearWalls = walls.filter(w => Utils.dist(agent, w) < 30);
                if (!nearWalls.length) return {x: agent.x, y: agent.y};
                const wall = nearWalls.reduce((n, w) => Utils.dist(agent, w) < Utils.dist(agent, n) ? w : n);
                const toWall = Utils.normalize(wall.x - agent.x, wall.y - agent.y);
                const tangent = {x: -toWall.y, y: toWall.x};
                
                // üîß Network can choose tangent direction
                if (networkOutputs && networkOutputs.length >= 12 && networkOutputs[9] < 0) {
                    return {x: agent.x - tangent.x * 25, y: agent.y - tangent.y * 25};
                }
                return {x: agent.x + tangent.x * 25, y: agent.y + tangent.y * 25};
            }
            default: return {x: agent.x, y: agent.y};
        }
    }
}

// ============================================================================
// 4. SMART POINT
// ============================================================================

class SmartPoint {
    constructor(x, y, type='normal') {
        this.x = x; this.y = y;
        this.type = type;
        this.collected = false;
        this.value = type==='rare' ? 20 : (type==='scared' ? 8 : 5);
        this.fleeRadius = type==='scared' ? 7 : 0;
        this.color = type==='rare' ? '#ffaa00' : (type==='scared' ? '#ff66cc' : '#00ff9d');
        this.radius = type==='rare' ? 6 : 4;
        this.vx = 0; this.vy = 0;
    }
    
    update(nearestAgent, dt) {
        if (this.collected) return;
        if (this.type === 'scared' && nearestAgent && Utils.dist(this, nearestAgent) < this.fleeRadius) {
            const away = Utils.normalize(this.x - nearestAgent.x, this.y - nearestAgent.y);
            this.vx = Utils.lerp(this.vx, away.x * 1.5, 0.1);
            this.vy = Utils.lerp(this.vy, away.y * 1.5, 0.1);
        } else {
            this.vx = Utils.lerp(this.vx, Utils.rand(-0.3, 0.3), 0.02);
            this.vy = Utils.lerp(this.vy, Utils.rand(-0.3, 0.3), 0.02);
        }
        this.x += this.vx * dt;
        this.y += this.vy * dt;
        this.x = Utils.clamp(this.x, 20, 800);
        this.y = Utils.clamp(this.y, 20, 580);
    }
    
    draw(ctx) {
        if (this.collected) return;
        ctx.fillStyle = this.color;
        ctx.beginPath();
        ctx.arc(this.x, this.y, this.radius, 0, Math.PI*2);
        ctx.fill();
        if (this.type === 'rare') {
            ctx.strokeStyle = '#ffdd44';
            ctx.lineWidth = 2;
            ctx.stroke();
        }
    }
}

// ============================================================================
// 4.5 ENEMY PREDICTOR ‚Äî –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ö–æ–¥–æ–≤ –ø—Ä–æ—Ç–∏–≤–Ω–∏–∫–∞
// ============================================================================

class EnemyPredictor {
    constructor() {
        this.history = [];
        this.maxHistory = 50;
        this.patterns = {
            'movingRight': 0,
            'movingLeft': 0,
            'movingDown': 0,
            'movingUp': 0,
            'fleeing': 0,
            'aggressive': 0,
            'unpredictable': 0
        };
    }

    recordMove(action, distance, health, aggression) {
        this.history.push({
            action: {...action},
            distance: distance,
            health: health,
            aggression: aggression,
            time: Date.now()
        });
        if (this.history.length > this.maxHistory) {
            this.history.shift();
        }
    }

    predictNextAction() {
        if (this.history.length < 5) return 'unpredictable';

        const recent = this.history.slice(-5);
        const avgX = recent.reduce((s, m) => s + (m.action?.fx || 0), 0) / recent.length;
        const avgY = recent.reduce((s, m) => s + (m.action?.fy || 0), 0) / recent.length;
        const avgAgg = recent.reduce((s, m) => s + (m.action?.aggression || 0.5), 0) / recent.length;

        // –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —à–∞–±–ª–æ–Ω
        if (Math.abs(avgAgg) > 0.7) {
            return avgAgg > 0 ? 'aggressive' : 'fleeing';
        } else if (Math.abs(avgX) > 0.6) {
            return avgX > 0 ? 'movingRight' : 'movingLeft';
        } else if (Math.abs(avgY) > 0.6) {
            return avgY > 0 ? 'movingDown' : 'movingUp';
        }
        return 'unpredictable';
    }

    getWeakpoints() {
        if (this.history.length < 5) return [];
        const recent = this.history.slice(-10);
        return recent
            .filter(m => m.health < 0.5)
            .map(m => ({direction: m.action, health: m.health}));
    }
}

// ============================================================================
// 4.6 STRATEGY MEMORY ‚Äî –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–±–µ–¥–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
// ============================================================================

class StrategyMemory {
    constructor() {
        this.winningStrategies = [];
        this.fightHistory = {};
        this.maxStrategies = 20;
    }

    recordFight(opponentId, won, weights, tactics, accuracy) {
        if (!this.fightHistory[opponentId]) {
            this.fightHistory[opponentId] = {wins: 0, losses: 0, lastTactics: null, bestAccuracy: 0};
        }
        
        const hist = this.fightHistory[opponentId];
        if (won) {
            hist.wins++;
            hist.lastTactics = tactics;
            hist.bestAccuracy = Math.max(hist.bestAccuracy, accuracy || 0);
        } else {
            hist.losses++;
        }
    }

    saveWinningStrategy(weights, opponentId, tactics, accuracy) {
        // –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø–æ–±–µ–¥–∏–ª–∏ —Å —Ö–æ—Ä–æ—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é (>65%)
        if (accuracy > 0.65) {
            this.winningStrategies.push({
                weights: JSON.parse(JSON.stringify(weights)), // Deep clone
                against: opponentId,
                tactics: tactics,
                winRate: accuracy,
                timestamp: Date.now()
            });
            
            if (this.winningStrategies.length > this.maxStrategies) {
                // –£–¥–∞–ª—è–µ–º –Ω–∞–∏–º–µ–Ω–µ–µ —É—Å–ø–µ—à–Ω—É—é
                this.winningStrategies.sort((a, b) => a.winRate - b.winRate);
                this.winningStrategies.shift();
            }
        }
    }

    loadSimilarStrategy(opponentId) {
        const strategies = this.winningStrategies.filter(s => s.against === opponentId);
        if (strategies.length > 0) {
            return strategies[strategies.length - 1]; // –ü–æ—Å–ª–µ–¥–Ω—è—è (ÊúÄÊñ∞)
        }
        return null;
    }
}

// ============================================================================
// 5. AGENT v2.1.2 ‚Äî DUAL-MEMORY ARCHITECTURE (WITH NEURAL CONTROL FIXES)
// ============================================================================

class Agent {
    constructor(id, x, y, color, seed) {
        this.id = id; this.x = x; this.y = y;
        this.color = color; this.vx = 0; this.vy = 0;
        this.health = 1; this.maxHealth = 1;
        this.seed = seed;
        
        this.net = new NeuralNetwork({
            inputDim: 24, hidden1: 48, hidden2: 36, outputDim: 16,
            memoryDim: 16, seed: seed + '_NET', lr: 0.005, hebbianRate: 0.002
        });
        
        this.arbiter = new BehaviorArbiter();
        this.mode = 'explore';
        this.target = {x, y};
        this.speed = 1;
        this.stuckCounter = 0;
        this.lastPos = {x, y};
        this.cumulativeReward = 0;
        this.alive = true;
        
        this.permanent = {
            skills: {
                hunting: 0.3 + Math.random()*0.2,
                fleeing: 0.4 + Math.random()*0.2,
                combat: 0.2 + Math.random()*0.2,
                exploring: 0.5,
                avoiding: 0.6
            },
            strategies: {
                huntPattern: 'direct',
                fleeDirection: 'away',
                combatStyle: 'direct'
            },
            preferences: {
                foodType: 'any',
                enemyType: 'any',
                territory: 'any'
            },
            muscleMemory: new Float32Array(16).fill(0),
            memory: {
                lastFoodPos: null,
                lastFoodStep: 0,
                visited: new Set(),
                unvisited: []
            }
        };

        this.predictive = {
            shortTerm: {
                positions: [],
                actions: [],
                results: [],
                enemyHistory: [],
                foodHistory: []
            },
            patterns: {
                enemyMovement: null,
                foodSpawn: null,
                dangerZones: new Map()
            },
            predictions: {
                enemyPos: {x:0, y:0},
                foodPos: {x:0, y:0},
                collision: false,
                success: 0.5
            },
            confidence: 0.5,
            predictionError: 0
        };
        
        // ‚úÖ –ù–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã –±–æ–µ–≤–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        this.enemyPredictor = new EnemyPredictor();
        this.strategyMemory = new StrategyMemory();
        this.currentTactic = 'aggressive';
        this.fightStartTime = 0;
        this.fightOpponent = null;
        
        this.wins = 0; this.mutations = 0;
        this.trail = [];
        this.lastDecision = null;
    }
    
    getInputs(world) {
        const inputs = [];
        const maxDist = Math.sqrt(820**2 + 600**2);
        
        const points = world.points.filter(p => !p.collected)
            .map(p => ({...p, d: Utils.dist(this, p)}))
            .sort((a,b) => a.d - b.d).slice(0,3);
        for(let i=0; i<3; i++) {
            const p = points[i];
            if (p) {
                inputs.push(Utils.clamp((p.x - this.x)/maxDist, -1, 1));
                inputs.push(Utils.clamp((p.y - this.y)/maxDist, -1, 1));
            } else {
                inputs.push(Utils.clamp(Utils.rand(-0.1, 0.1), -1, 1));
                inputs.push(Utils.clamp(Utils.rand(-0.1, 0.1), -1, 1));
            }
        }
        
        const enemies = world.enemies.filter(e => e.id !== this.id && e.alive)
            .map(e => ({...e, d: Utils.dist(this, e)}))
            .sort((a,b) => a.d - b.d).slice(0,3);
        for(let i=0; i<3; i++) {
            const e = enemies[i];
            if (e) {
                inputs.push(Utils.clamp((e.x - this.x)/maxDist, -1, 1));
                inputs.push(Utils.clamp((e.y - this.y)/maxDist, -1, 1));
            } else {
                inputs.push(Utils.clamp(Utils.rand(-0.1, 0.1), -1, 1));
                inputs.push(Utils.clamp(Utils.rand(-0.1, 0.1), -1, 1));
            }
        }
        
        const walls = world.walls
            .map(w => ({...w, d: Utils.dist(this, w)}))
            .sort((a,b) => a.d - b.d).slice(0,2);
        for(let i=0; i<2; i++) {
            const w = walls[i];
            if (w) {
                inputs.push(Utils.clamp((w.x - this.x)/maxDist, -1, 1));
                inputs.push(Utils.clamp((w.y - this.y)/maxDist, -1, 1));
            } else {
                inputs.push(Utils.clamp(Utils.rand(-0.1, 0.1), -1, 1));
                inputs.push(Utils.clamp(Utils.rand(-0.1, 0.1), -1, 1));
            }
        }
        
        inputs.push(Utils.clamp((400 - this.x)/400, -1, 1));
        inputs.push(Utils.clamp((300 - this.y)/300, -1, 1));
        inputs.push(this.health);
        inputs.push(Utils.clamp(world.step/2000, 0, 1));
        inputs.push(Utils.clamp(world.points.filter(p => !p.collected && Utils.dist(this,p)<100).length/10, 0, 1));
        inputs.push(Utils.clamp(world.enemies.filter(e => e.id!==this.id && e.alive && Utils.dist(this,e)<100).length/5, 0, 1));
        inputs.push(Utils.clamp(Math.min(this.x, 820-this.x, this.y, 600-this.y)/100, 0, 1));
        inputs.push(Utils.clamp(this.cumulativeReward/20, -1, 1));
        
        return inputs.map(v => Utils.safeNumber(v, 0));
    }
    
    updatePredictiveMemory(world) {
        this.predictive.shortTerm.positions.push({x: this.x, y: this.y});
        if (this.predictive.shortTerm.positions.length > 20) {
            this.predictive.shortTerm.positions.shift();
        }
        
        const enemies = world.enemies.filter(e => e.id !== this.id && e.alive);
        if (enemies.length > 0) {
            const enemy = enemies[0];
            this.predictive.shortTerm.enemyHistory.push({x: enemy.x, y: enemy.y});
            if (this.predictive.shortTerm.enemyHistory.length > 5) {
                this.predictive.shortTerm.enemyHistory.shift();
            }
            
            const hist = this.predictive.shortTerm.enemyHistory;
            if (hist.length >= 2) {
                const [prev, last] = [hist[hist.length-2], hist[hist.length-1]];
                const dx = last.x - prev.x;
                const dy = last.y - prev.y;
                this.predictive.predictions.enemyPos = {
                    x: last.x + dx * 0.75,
                    y: last.y + dy * 0.75
                };
                
                const error = Utils.dist(enemy, this.predictive.predictions.enemyPos);
                this.predictive.predictionError = Utils.lerp(
                    this.predictive.predictionError, 
                    error / 50,
                    0.1
                );
            }
        }
        
        const nearbyFood = world.points.filter(p => !p.collected && Utils.dist(this, p) < 80);
        if (nearbyFood.length > 0) {
            const food = nearbyFood[0];
            this.predictive.shortTerm.foodHistory.push({x: food.x, y: food.y});
            if (this.predictive.shortTerm.foodHistory.length > 3) {
                this.predictive.shortTerm.foodHistory.shift();
            }
            
            if (this.predictive.shortTerm.foodHistory.length >= 2) {
                const avgX = this.predictive.shortTerm.foodHistory.reduce((s, f) => s + f.x, 0) / 
                            this.predictive.shortTerm.foodHistory.length;
                const avgY = this.predictive.shortTerm.foodHistory.reduce((s, f) => s + f.y, 0) / 
                            this.predictive.shortTerm.foodHistory.length;
                this.predictive.predictions.foodPos = {x: avgX, y: avgY};
            }
        }
        
        if (enemies.length > 0 && this.predictive.shortTerm.enemyHistory.length >= 2) {
            const enemy = enemies[0];
            const predicted = this.predictive.predictions.enemyPos;
            const error = Utils.dist(enemy, predicted);
            const accuracy = Utils.clamp(1 - error / 60, 0, 1);
            this.predictive.confidence = Utils.lerp(this.predictive.confidence, accuracy, 0.08);
        }
    }
    
    updatePermanentSkills(reward, mode, skillGrowthRate) {
        if (reward <= 3 || !settings.enableSkillEvolution) return;
        
        const skillMap = {
            'hunt': 'hunting', 'flee': 'fleeing',
            'combat': 'combat', 'explore': 'exploring', 'avoid': 'avoiding'
        };
        const skillKey = skillMap[mode];
        
        if (skillKey && this.permanent.skills[skillKey] !== undefined) {
            const correlations = {
                hunting: { combat: 0.4, exploring: 0.2 },
                combat: { hunting: 0.4, fleeing: -0.3 },
                fleeing: { avoiding: 0.3, exploring: 0.1 },
                exploring: { hunting: 0.2, avoiding: 0.1 },
                avoiding: { fleeing: 0.3, exploring: 0.1 }
            };
            
            const growth = skillGrowthRate * reward * 0.1;
            this.permanent.skills[skillKey] = Utils.clamp(
                this.permanent.skills[skillKey] + growth,
                0, 1
            );
            
            if (correlations[skillKey]) {
                for (const [related, corr] of Object.entries(correlations[skillKey])) {
                    if (this.permanent.skills[related] !== undefined) {
                        const relatedGrowth = growth * corr * 0.5;
                        this.permanent.skills[related] = Utils.clamp(
                            this.permanent.skills[related] + relatedGrowth,
                            0, 1
                        );
                    }
                }
            }
        }
    }
    
    updateMuscleMemory(outputs, reward) {
        if (reward < 4) return;
        
        for (let i = 0; i < Math.min(16, outputs.length); i++) {
            const diff = Math.abs(outputs[i] - this.permanent.muscleMemory[i]);
            if (diff > 0.12 && Math.abs(outputs[i]) > 0.4) {
                this.permanent.muscleMemory[i] = Utils.lerp(
                    this.permanent.muscleMemory[i], 
                    outputs[i], 
                    0.06
                );
            }
        }
    }
    
    // ‚úÖ –ë–û–ï–í–´–ï –¢–ê–ö–¢–ò–ö–ò (Combat Tactics)
    selectCombatTactic(enemyDistance, enemyHealth, myHealth, enemyPrediction) {
        const tactics = ['aggressive', 'kite', 'dodge', 'bait', 'defensive'];
        
        // –í—ã–±–∏—Ä–∞–µ–º —Ç–∞–∫—Ç–∏–∫—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –≤—Ä–∞–≥–∞
        if (enemyPrediction === 'fleeing') {
            return 'aggressive';  // –î–∞–≤–∏–º —É–±–µ–≥–∞—é—â–µ–≥–æ
        } else if (enemyPrediction === 'aggressive') {
            return myHealth < 0.4 ? 'dodge' : 'kite';  // –ò–∑–±–µ–≥–∞–µ–º –∏–ª–∏ –∫—Ä—É–≥–æ–≤–æ–π –º–∞–Ω–µ–≤—Ä
        } else if (enemyHealth < 0.3) {
            return 'aggressive';  // –î–æ–±–∏–≤–∞–µ–º
        } else if (myHealth < 0.3) {
            return 'defensive';  // –ó–∞—â–∏—â–∞–µ–º—Å—è
        } else if (enemyDistance < 20) {
            return 'bait';  // –ü—Ä–æ–≤–æ—Ü–∏—Ä—É–µ–º –æ—à–∏–±–∫—É –≤—Ä–∞–≥–∞
        }
        return 'adaptive';  // –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è —Ç–∞–∫—Ç–∏–∫–∞ (–ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è)
    }
    
    // ‚úÖ –î–ò–ù–ê–ú–ò–ß–ï–°–ö–û–ï –í–ù–ò–ú–ê–ù–ò–ï –ö –í–†–ê–ì–£
    computeAttentionMask(enemyDistance, myHealth) {
        let mask = {
            combat: 0.1,    // –§–æ–∫—É—Å –Ω–∞ –≤—Ä–∞–≥–µ
            spatial: 0.5,   // –ö–∞—Ä—Ç–∞ –º–µ—Å—Ç–Ω–æ—Å—Ç–∏
            memory: 0.2,    // –ò—Å—Ç–æ—Ä–∏—è
            survival: 0.2   // –í—ã–∂–∏–≤–∞–Ω–∏–µ
        };
        
        // –ï—Å–ª–∏ –≤—Ä–∞–≥ –±–ª–∏–∑–∫–æ ‚Äî —É—Å–∏–ª–∏–≤–∞–µ–º —Ñ–æ–∫—É—Å –Ω–∞ –Ω–µ–º
        if (enemyDistance < 50) {
            const closeness = 1 - (enemyDistance / 50);
            mask.combat = 0.5 + closeness * 0.4;
            mask.spatial = 0.3 - closeness * 0.2;
            mask.memory = 0.1;
        }
        
        // –ï—Å–ª–∏ –∑–¥–æ—Ä–æ–≤—å–µ –Ω–∏–∑–∫–æ–µ ‚Äî —Ñ–æ–∫—É—Å–∏—Ä—É–µ–º—Å—è –Ω–∞ –≤—ã–∂–∏–≤–∞–Ω–∏–∏
        if (myHealth < 0.3) {
            mask.survival = 0.4;
            mask.combat = Math.max(0.2, mask.combat - 0.2);
        }
        
        return mask;
    }
    
    decideCombatAction(enemy, world) {
        const distance = Utils.dist(this, enemy);
        const prediction = this.enemyPredictor.predictNextAction();
        
        this.currentTactic = this.selectCombatTactic(
            distance, 
            enemy.health, 
            this.health, 
            prediction
        );
        
        this.fightOpponent = enemy.id;
        this.fightStartTime = Date.now();
        
        return this.currentTactic;
    }

    decide(world) {
        this.updatePredictiveMemory(world);
        
        const inputs = this.getInputs(world);
        const { output } = this.net.forward(inputs);
        const behaviors = this.arbiter.decode(output);
        
        const enemies = world.enemies.filter(e => e.id !== this.id && e.alive);
        const context = {
            enemyDistance: enemies.length ? Math.min(...enemies.map(e => Utils.dist(this, e))) : 999,
            wallDistance: world.walls.length ? Math.min(...world.walls.map(w => Utils.dist(this, w))) : 999,
            health: this.health
        };
        
        const { mode, behaviors: weighted } = this.arbiter.select(
            behaviors, 
            context, 
            settings.enableSkillEvolution ? this.permanent.skills : null
        );
        this.mode = mode;
        
        // üîß FIX #3: Pass network outputs to calculateTarget for neural modulation
        let target = this.arbiter.calculateTarget(mode, weighted, this, {
            points: world.points, 
            enemies: world.enemies,
            walls: world.walls
        }, output); // ‚Üê Pass outputs here
        
        // üîß FIX #6: Target validation
        if (!target || typeof target.x !== 'number' || !isFinite(target.x) || 
            typeof target.y !== 'number' || !isFinite(target.y)) {
            console.warn(`Invalid target for ${this.id} in mode ${mode}`, target);
            target = {
                x: Utils.clamp(this.x + Utils.rand(-50, 50), 30, 790),
                y: Utils.clamp(this.y + Utils.rand(-50, 50), 30, 570)
            };
        }
        
        this.target = target;
        
        const confidenceMod = this.predictive.confidence > 0.7 ? 1.1 : (this.predictive.confidence < 0.4 ? 0.9 : 1);
        this.speed = Utils.lerp(this.speed, weighted.speed * 2.5 * confidenceMod + 0.5, 0.08);
        
        if (mode === 'hunt' && weighted.memoryWeight > 0.5) {
            const nearby = world.points.filter(p => !p.collected && Utils.dist(this,p)<20);
            if (nearby.length && !this.permanent.memory.lastFoodPos) {
                this.permanent.memory.lastFoodPos = {...nearby[0]};
                this.permanent.memory.lastFoodStep = world.step;
            }
        }
        
        const cell = `${Math.floor(this.x/25)},${Math.floor(this.y/25)}`;
        if (!this.permanent.memory.visited.has(cell)) {
            this.permanent.memory.visited.add(cell);
            if (this.permanent.memory.unvisited.length > 60) this.permanent.memory.unvisited.shift();
            this.permanent.memory.unvisited.push({
                x: this.x + Utils.rand(-40,40), 
                y: this.y + Utils.rand(-30,30)
            });
        }
        
        this.lastDecision = { mode, behaviors: weighted, inputs, output };
        
        return { target: this.target, speed: this.speed, mode, behaviors: weighted, inputs, output };
    }
    
    // üîß FIX #1: Wall repulsion conflict resolution + guaranteed movement + NEURAL MODULATION
    move(target, speed, walls, dt, networkOutputs = null) {
        const desired = Utils.normalize(target.x - this.x, target.y - this.y);
        const wallRep = this.getWallRepulsion(walls);
        
        let finalDir;
        
        // üîß –ï—Å–ª–∏ repulsion —Å–ª–∏—à–∫–æ–º —Å–∏–ª—å–Ω—ã–π - –∏—â–µ–º –æ–±—Ö–æ–¥ –ø–æ –∫–∞—Å–∞—Ç–µ–ª—å–Ω–æ–π
        if (wallRep.strength > 0.8) {
            const tangent = {x: -wallRep.y, y: wallRep.x};
            const noise = Utils.rand(-0.3, 0.3);
            finalDir = {
                x: tangent.x + noise,
                y: tangent.y + noise
            };
            const mag = Math.hypot(finalDir.x, finalDir.y) || 1;
            finalDir.x /= mag;
            finalDir.y /= mag;
        } else {
            // –û–±—ã—á–Ω–æ–µ —Å–º–µ—à–∏–≤–∞–Ω–∏–µ
            finalDir = {
                x: Utils.lerp(desired.x, wallRep.x, wallRep.strength * 0.6),
                y: Utils.lerp(desired.y, wallRep.y, wallRep.strength * 0.6)
            };
            
            const mag = Math.hypot(finalDir.x, finalDir.y);
            
            // üîß –ï—Å–ª–∏ –≤–µ–∫—Ç–æ—Ä–∞ –ø–æ–≥–∞—Å–∏–ª–∏ –¥—Ä—É–≥ –¥—Ä—É–≥–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —á–∏—Å—Ç—ã–π desired
            if (mag < 0.1) {
                finalDir = desired;
            } else {
                finalDir.x /= mag;
                finalDir.y /= mag;
            }
        }
        
        // ‚úÖ –ù–û–í–û–ï: –ü—Ä–∏–º–µ–Ω–∏—Ç—å –±–æ–µ–≤—É—é —Ç–∞–∫—Ç–∏–∫—É –µ—Å–ª–∏ –≤ —Ä–µ–∂–∏–º–µ –±–æ—è
        if (this.currentTactic && this.currentTactic !== 'adaptive') {
            finalDir = this.executeTactic(finalDir, target, walls);
        }
        
        // üîß FIX #3: Neural network can modulate final direction (outputs[12-13])
        if (networkOutputs && networkOutputs.length >= 14) {
            const neuralModX = Utils.tanh(networkOutputs[12] || 0) * 0.2;
            const neuralModY = Utils.tanh(networkOutputs[13] || 0) * 0.2;
            finalDir.x = Utils.clamp(finalDir.x + neuralModX, -1, 1);
            finalDir.y = Utils.clamp(finalDir.y + neuralModY, -1, 1);
            // Re-normalize
            const mag = Math.hypot(finalDir.x, finalDir.y) || 1;
            finalDir.x /= mag;
            finalDir.y /= mag;
        }
        
        // üîß FIX #1: Guaranteed minimum velocity to prevent stuck states
        const minSpeed = 0.3;
        const actualSpeed = Math.max(speed, minSpeed);
        
        this.vx = Utils.lerp(this.vx, finalDir.x * actualSpeed, 0.15);
        this.vy = Utils.lerp(this.vy, finalDir.y * actualSpeed, 0.15);
        
        // üîß FIX #1: Prevent zero velocity (anti-stuck failsafe)
        if (Math.abs(this.vx) < 0.02) this.vx = finalDir.x * minSpeed;
        if (Math.abs(this.vy) < 0.02) this.vy = finalDir.y * minSpeed;
        
        this.x += this.vx * dt;
        this.y += this.vy * dt;
        
        if (this.x < 20) { this.x = 20; this.vx *= -0.4; }
        if (this.x > 800) { this.x = 800; this.vx *= -0.4; }
        if (this.y < 20) { this.y = 20; this.vy *= -0.4; }
        if (this.y > 580) { this.y = 580; this.vy *= -0.4; }
        
        for(const w of walls) {
            if (Utils.dist(this, w) < 15) {
                const push = Utils.normalize(this.x - w.x, this.y - w.y);
                this.x += push.x * 0.6;
                this.y += push.y * 0.6;
                this.vx *= -0.25; this.vy *= -0.25;
            }
        }
    }
    
    // ‚úÖ –ù–û–í–û–ï: –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –±–æ–µ–≤–æ–π —Ç–∞–∫—Ç–∏–∫–∏
    executeTactic(direction, target, walls) {
        const tactic = this.currentTactic;
        let tacticDir = {...direction};
        
        switch(tactic) {
            case 'aggressive': {
                // –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –∏–º–ø—É–ª—å—Å –∫ –≤—Ä–∞–≥—É
                tacticDir.x *= 1.3;
                tacticDir.y *= 1.3;
                break;
            }
            case 'kite': {
                // –ö—Ä—É–≥–æ–≤–æ–π –º–∞–Ω–µ–≤—Ä –≤–æ–∫—Ä—É–≥ –≤—Ä–∞–≥–∞
                const angle = Math.atan2(direction.y, direction.x) + Math.PI / 2;
                tacticDir = {
                    x: Math.cos(angle) * 0.8,
                    y: Math.sin(angle) * 0.8
                };
                break;
            }
            case 'dodge': {
                // –ü–µ—Ä–ø–µ–Ω–¥–∏–∫—É–ª—è—Ä–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ
                const angle = Math.atan2(direction.y, direction.x) + (Math.random() > 0.5 ? 1 : -1) * Math.PI / 3;
                tacticDir = {
                    x: Math.cos(angle),
                    y: Math.sin(angle)
                };
                break;
            }
            case 'bait': {
                // –ü—Ä–∏—Ç–≤–æ—Ä—è–µ–º—Å—è —Å–ª–∞–±—ã–º–∏ (–º–µ–¥–ª–µ–Ω–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ)
                tacticDir.x *= 0.3;
                tacticDir.y *= 0.3;
                break;
            }
            case 'defensive': {
                // –û—Ç—Å—Ç—É–ø–∞–µ–º, –Ω–æ –≥–æ—Ç–æ–≤—ã –∫–æ–Ω—Ç—Ä–∞—Ç–∞–∫–æ–≤–∞—Ç—å
                tacticDir.x *= -0.6;
                tacticDir.y *= -0.6;
                break;
            }
        }
        
        // –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        const mag = Math.hypot(tacticDir.x, tacticDir.y) || 1;
        tacticDir.x /= mag;
        tacticDir.y /= mag;
        
        return tacticDir;
    }
    
    getWallRepulsion(walls) {
        let repulsion = {x:0, y:0};
        for(const w of walls) {
            const d = Utils.dist(this, w);
            if (d < 40) {
                const force = (40 - d) / 40;
                const away = Utils.normalize(this.x - w.x, this.y - w.y);
                repulsion.x += away.x * force;
                repulsion.y += away.y * force;
            }
        }
        const mag = Math.hypot(repulsion.x, repulsion.y);
        return mag > 0 ? {x: repulsion.x/mag, y: repulsion.y/mag, strength: Utils.clamp(mag, 0, 1)} : {x:0, y:0, strength:0};
    }
    
    // üîß FIX #2: Point collection with increased radius + force collection fallback
    calculateReward(world, decision) {
        let reward = 0;
        let collectedAny = false;
        
        for(const p of world.points) {
            if (!p.collected) {
                const d = Utils.dist(this, p);
                // üîß FIX: –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π —Ä–∞–¥–∏—É—Å —Å–±–æ—Ä–∞: 12‚Üí18
                if (d < 18) {
                    p.collected = true;
                    reward += p.value;
                    collectedAny = true;
                    
                    if (d > 14) {
                        console.log(`Point collected at distance ${d.toFixed(1)}`);
                    }
                }
            }
        }
        
        // üîß FIX: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π —Å–±–æ—Ä –µ—Å–ª–∏ —Ç–æ—á–∫–∞ –æ—á–µ–Ω—å –±–ª–∏–∑–∫–æ
        const veryNear = world.points.find(p => !p.collected && Utils.dist(this, p) < 10);
        if (veryNear) {
            veryNear.collected = true;
            reward += veryNear.value;
            console.log('Force collected');
        }
        
        const newCell = `${Math.floor(this.x/25)},${Math.floor(this.y/25)}`;
        if (!this.permanent.memory.visited.has(newCell)) reward += 0.06;
        
        const moved = Math.hypot(this.x - this.lastPos.x, this.y - this.lastPos.y);
        if (moved < 0.6) {
            this.stuckCounter++;
        } else {
            this.stuckCounter = 0;
        }
        
        if (this.stuckCounter > 20) {
            this.target = {
                x: Utils.clamp(this.x + Utils.rand(-100,100), 30, 790),
                y: Utils.clamp(this.y + Utils.rand(-80,80), 30, 570)
            };
            this.stuckCounter = 0;
            return -0.5;
        }
        
        this.lastPos = {x: this.x, y: this.y};
        
        if (Math.min(this.x, 820-this.x, this.y, 600-this.y) < 12) reward -= 0.03;
        reward -= (1 - this.health) * 0.12;
        
        this.cumulativeReward += reward;
        return reward;
    }
    
    learn(reward, decision) {
        if (!decision) return;
        
        if (reward > 0.1 && settings.enableTraining) {
            this.net.hebbianUpdate(decision.inputs, decision.output, reward);
        }
        
        if (reward > 3 && settings.enableSkillEvolution) {
            this.updatePermanentSkills(reward, decision.mode, settings.skillGrowthRate);
        }
        
        if (reward > 4) {
            this.updateMuscleMemory(decision.output, reward);
        }
    }
    
    evolve(mutationRate = 0.1) {
        if (!settings.enableEvolution) return 0;
        const mutations = this.net.mutate(mutationRate, 0.15);
        this.mutations += mutations;
        return mutations;
    }
    
    reset(x, y) {
        this.x = x; this.y = y;
        this.vx = 0; this.vy = 0;
        this.health = 1;
        this.stuckCounter = 0;
        this.lastPos = {x, y};
        this.cumulativeReward = 0;
        this.mode = 'explore';
        this.target = {x, y};
        this.trail = [];
        this.predictive.confidence = 0.5;
        this.predictive.predictionError = 0;
        this.net.memory.fill(0);
    }
    
    draw(ctx, showVision = false, showTrail = true) {
        if (showTrail && this.trail.length > 1) {
            ctx.beginPath();
            ctx.moveTo(this.trail[0].x, this.trail[0].y);
            for(let i=1; i<this.trail.length; i++) {
                const t = this.trail[i];
                const alpha = 1 - t.age/80;
                ctx.strokeStyle = this.color + Math.floor(alpha * 40).toString(16).padStart(2, '0');
                ctx.lineTo(t.x, t.y);
            }
            ctx.stroke();
        }
        
        ctx.fillStyle = this.color;
        ctx.beginPath();
        ctx.arc(this.x, this.y, 11, 0, Math.PI*2);
        ctx.fill();
        
        ctx.strokeStyle = '#fff';
        ctx.lineWidth = 2;
        ctx.beginPath();
        ctx.moveTo(this.x, this.y);
        ctx.lineTo(this.x + this.vx*7, this.y + this.vy*7);
        ctx.stroke();
        
        const modeColors = {
            hunt: '#00ff9d', flee: '#ff5577', explore: '#00d4ff',
            combat: '#ffaa00', avoid: '#aa88ff'
        };
        ctx.strokeStyle = modeColors[this.mode] || '#888';
        ctx.lineWidth = 2.5;
        ctx.beginPath();
        ctx.arc(this.x, this.y, 15, 0, Math.PI*2);
        ctx.stroke();
        
        ctx.fillStyle = this.predictive.confidence > 0.7 ? '#00ff9d' : 
                       (this.predictive.confidence < 0.4 ? '#ff5577' : '#ffaa00');
        ctx.beginPath();
        ctx.arc(this.x + 14, this.y - 14, 3, 0, Math.PI*2);
        ctx.fill();
        
        if (this.health < 1) {
            ctx.fillStyle = '#222';
            ctx.fillRect(this.x-14, this.y-20, 28, 4);
            ctx.fillStyle = this.health > 0.5 ? '#00ff9d' : '#ff5577';
            ctx.fillRect(this.x-14, this.y-20, 28*this.health, 4);
        }
        
        if (showVision && this.mode === 'hunt') {
            ctx.strokeStyle = 'rgba(0,255,157,0.25)';
            ctx.fillStyle = 'rgba(0,255,157,0.08)';
            ctx.beginPath();
            ctx.moveTo(this.x, this.y);
            ctx.arc(this.x, this.y, 70, Math.atan2(this.vy, this.vx)-0.5, Math.atan2(this.vy, this.vx)+0.5);
            ctx.closePath();
            ctx.fill();
            ctx.stroke();
        }
        
        ctx.strokeStyle = 'rgba(255,255,255,0.35)';
        ctx.setLineDash([4,3]);
        ctx.beginPath();
        ctx.moveTo(this.x, this.y);
        ctx.lineTo(this.target.x, this.target.y);
        ctx.stroke();
        ctx.setLineDash([]);
        
        if (this.trail.length === 0 || this.trail[this.trail.length-1].age > 4) {
            this.trail.push({x: this.x, y: this.y, age: 0});
            if (this.trail.length > 35) this.trail.shift();
        }
        this.trail.forEach(t => t.age++);
    }
    
    getDebugInfo() {
        return {
            mode: this.mode,
            target: `${Math.round(this.target.x)},${Math.round(this.target.y)}`,
            speed: this.speed.toFixed(2),
            aggro: this.lastDecision?.behaviors?.aggression?.toFixed(2) || '‚Äî',
            memory: (this.permanent.memory.visited.size/100).toFixed(2),
            neurons: this.net.activeNeurons.slice(0,3).join(','),
            reward: this.cumulativeReward.toFixed(2),
            stuck: this.stuckCounter,
            confidence: this.predictive.confidence.toFixed(2),
            predError: this.predictive.predictionError.toFixed(2)
        };
    }
    
    clone() {
        const agent = new Agent(this.id, this.x, this.y, this.color, this.seed + '_clone_' + Date.now());
        agent.net = this.net.clone();
        agent.health = this.health;
        agent.cumulativeReward = this.cumulativeReward;
        agent.wins = this.wins;
        agent.mutations = this.mutations;
        agent.permanent = {
            skills: {...this.permanent.skills},
            strategies: {...this.permanent.strategies},
            preferences: {...this.permanent.preferences},
            muscleMemory: new Float32Array(this.permanent.muscleMemory),
            memory: {
                lastFoodPos: this.permanent.memory.lastFoodPos ? {...this.permanent.memory.lastFoodPos} : null,
                lastFoodStep: this.permanent.memory.lastFoodStep || 0,
                visited: new Set(this.permanent.memory.visited),
                unvisited: this.permanent.memory.unvisited.map(p => ({...p}))
            }
        };
        agent.predictive = {
            shortTerm: { positions: [], actions: [], results: [], enemyHistory: [], foodHistory: [] },
            patterns: { enemyMovement: null, foodSpawn: null, dangerZones: new Map() },
            predictions: { enemyPos: {x:0,y:0}, foodPos: {x:0,y:0}, collision: false, success: 0.5 },
            confidence: this.predictive.confidence,
            predictionError: this.predictive.predictionError
        };
        return agent;
    }
    
    toJSON() {
        return {
            id: this.id, seed: this.seed, x: this.x, y: this.y,
            health: this.health, cumulativeReward: this.cumulativeReward,
            wins: this.wins, mutations: this.mutations,
            net: this.net.toJSON(),
            permanent: {
                skills: this.permanent.skills,
                strategies: this.permanent.strategies,
                preferences: this.permanent.preferences,
                muscleMemory: Array.from(this.permanent.muscleMemory),
                memory: {
                    lastFoodPos: this.permanent.memory.lastFoodPos,
                    lastFoodStep: this.permanent.memory.lastFoodStep,
                    visited: Array.from(this.permanent.memory.visited).slice(0, 100),
                    unvisited: this.permanent.memory.unvisited.slice(0, 30)
                }
            },
            predictive: {
                confidence: this.predictive.confidence,
                predictionError: this.predictive.predictionError
            },
            // ‚úÖ –ù–û–í–û–ï: –°–æ—Ö—Ä–∞–Ω—è–µ–º –±–æ–µ–≤—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
            strategyMemory: {
                winningStrategies: this.strategyMemory.winningStrategies.slice(0, 5), // –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ø-5
                fightHistory: this.strategyMemory.fightHistory
            }
        };
    }
    
    static fromJSON(data, color) {
        const agent = new Agent(data.id, data.x, data.y, color, data.seed);
        agent.net = NeuralNetwork.fromJSON(data.net);
        agent.health = data.health ?? 1;
        agent.cumulativeReward = data.cumulativeReward ?? 0;
        agent.wins = data.wins ?? 0;
        agent.mutations = data.mutations ?? 0;
        
        if (data.permanent) {
            agent.permanent.skills = {...(data.permanent.skills || agent.permanent.skills)};
            agent.permanent.strategies = {...(data.permanent.strategies || agent.permanent.strategies)};
            agent.permanent.preferences = {...(data.permanent.preferences || agent.permanent.preferences)};
            if (data.permanent.muscleMemory) {
                agent.permanent.muscleMemory = new Float32Array(data.permanent.muscleMemory);
            }
            if (data.permanent.memory) {
                agent.permanent.memory.lastFoodPos = data.permanent.memory.lastFoodPos;
                agent.permanent.memory.lastFoodStep = data.permanent.memory.lastFoodStep || 0;
                agent.permanent.memory.visited = new Set(data.permanent.memory.visited || []);
                agent.permanent.memory.unvisited = data.permanent.memory.unvisited || [];
            }
        }
        
        // ‚úÖ –ù–û–í–û–ï: –ó–∞–≥—Ä—É–∂–∞–µ–º –±–æ–µ–≤—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        if (data.strategyMemory) {
            agent.strategyMemory.winningStrategies = data.strategyMemory.winningStrategies || [];
            agent.strategyMemory.fightHistory = data.strategyMemory.fightHistory || {};
        }
        
        if (data.predictive) {
            agent.predictive.confidence = data.predictive.confidence ?? 0.5;
            agent.predictive.predictionError = data.predictive.predictionError ?? 0;
        }
        
        return agent;
    }
}

// ============================================================================
// 6. WORLD
// ============================================================================

class World {
    constructor(width, height) {
        this.width = width; this.height = height;
        this.step = 0; this.episode = 0;
        this.points = []; this.walls = []; this.enemies = [];
        this.reset();
    }
    
    reset() {
        this.step = 0;
        this.points = []; this.walls = [];
        
        for(let i=0; i<40; i++) this.points.push(new SmartPoint(
            35+Utils.rand(0,750), 35+Utils.rand(0,530), 'normal'
        ));
        for(let i=0; i<8; i++) this.points.push(new SmartPoint(
            35+Utils.rand(0,750), 35+Utils.rand(0,530), 'scared'
        ));
        for(let i=0; i<2; i++) this.points.push(new SmartPoint(
            35+Utils.rand(0,750), 35+Utils.rand(0,530), 'rare'
        ));
        
        for(let i=0; i<12; i++) {
            this.walls.push({
                x: 60+Utils.rand(0,700),
                y: 60+Utils.rand(0,460)
            });
        }
    }
    
    spawnAgents() {
        this.enemies = [
            new Agent('blue', 120, 300, '#00d4ff', 'ARENA_V2_BLUE_' + Date.now()),
            new Agent('red', 700, 300, '#ff5577', 'ARENA_V2_RED_' + (Date.now()+1))
        ];
    }
    
    update(dt) {
        this.step++;
        
        const nearestBlue = this.enemies[0];
        const nearestRed = this.enemies[1];
        for(const p of this.points) {
            const nearest = Utils.dist(p, nearestBlue) < Utils.dist(p, nearestRed) ? nearestBlue : nearestRed;
            p.update(nearest?.alive ? nearest : null, dt);
        }
        
        for(const agent of this.enemies) {
            if (!agent.alive) continue;
            
            // ‚úÖ –ù–û–í–û–ï: –û–±–Ω–æ–≤–ª—è–µ–º EnemyPredictor –≤–æ –≤—Ä–µ–º—è –±–æ—è
            const enemies = this.enemies.filter(e => e.id !== agent.id && e.alive);
            if (enemies.length > 0) {
                const enemy = enemies[0];
                const distance = Utils.dist(agent, enemy);
                
                // –ï—Å–ª–∏ –≤—Ä–∞–≥ –±–ª–∏–∑–∫–æ ‚Äî —É—á–∏—Ç—å—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –µ–≥–æ –¥–≤–∏–∂–µ–Ω–∏—è
                if (distance < 150) {
                    agent.enemyPredictor.recordMove(
                        agent.lastDecision?.behaviors || {},
                        distance,
                        enemy.health,
                        (agent.lastDecision?.behaviors?.aggression || 0.5)
                    );
                    
                    // ‚úÖ –ù–û–í–û–ï: –ü—Ä–∏–º–µ–Ω–∏—Ç—å –±–æ–µ–≤—É—é —Ç–∞–∫—Ç–∏–∫—É –µ—Å–ª–∏ –≤—Ä–∞–≥ –æ—á–µ–Ω—å –±–ª–∏–∑–∫–æ
                    if (distance < 100) {
                        agent.decideCombatAction(enemy, this);
                    }
                }
            }
            
            const decision = agent.decide(this);
            // üîß FIX #3: Pass network outputs to move() for neural modulation
            agent.move(decision.target, decision.speed, this.walls, dt, decision.output);
            
            const reward = agent.calculateReward(this, decision);
            agent.learn(reward, decision);
        }
        
        // ‚úÖ –ù–û–í–û–ï: –°–æ—Ö—Ä–∞–Ω—è—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø–æ—Å–ª–µ –±–æ—è
        for(const agent of this.enemies) {
            if (!agent.alive) {
                const winner = this.enemies.find(e => e.id !== agent.id && e.alive);
                
                if (winner && settings.enableEvolution) {
                    // –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–æ–±–µ–¥–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é
                    const accuracy = winner.wins / (winner.wins + 1);
                    winner.strategyMemory.saveWinningStrategy(
                        winner.net.W1, // –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ—Å–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
                        agent.id,      // ID –ø—Ä–æ–∏–≥—Ä–∞–≤—à–µ–≥–æ
                        winner.currentTactic,
                        accuracy
                    );
                    
                    winner.wins++;
                    Logger.log(`üèÜ ${winner.id.toUpperCase()} –ø–æ–±–µ–¥–∏–ª! –¢–∞–∫—Ç–∏–∫–∞: ${winner.currentTactic}`, 'success');
                    winner.evolve(settings.mutationRate);
                }
                
                agent.alive = false;
            }
        }
        
        const alive = this.enemies.filter(a => a.alive);
        if (alive.length < 2) {
            this.episode++;
            this.resetEpisode();
        }
        
        const active = this.points.filter(p => !p.collected).length;
        if (active < 22 && this.step % 40 === 0) {
            const types = ['normal','normal','normal','scared','rare'];
            this.points.push(new SmartPoint(
                35+Utils.rand(0,750), 35+Utils.rand(0,530),
                types[Utils.randInt(0, types.length-1)]
            ));
        }
        
        return {
            blue: this.enemies[0], red: this.enemies[1],
            pointsLeft: this.points.filter(p => !p.collected).length,
            episode: this.episode
        };
    }
    
    resetEpisode() {
        this.points.forEach(p => p.collected = false);
        this.enemies.forEach(a => {
            a.reset(a.id === 'blue' ? 120 : 700, 300);
            a.alive = true;
        });
    }
    
    // üîß FIX #5: Canvas properly cleared
    draw(ctx, vision = false, trail = true) {
        // üîß –ü–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ canvas
        ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);
        
        const grad = ctx.createLinearGradient(0,0,this.width,this.height);
        grad.addColorStop(0, '#0a0a15');
        grad.addColorStop(1, '#1a1a2e');
        ctx.fillStyle = grad;
        ctx.fillRect(0, 0, this.width, this.height);
        
        ctx.strokeStyle = 'rgba(50,50,90,0.25)';
        ctx.lineWidth = 1;
        for(let x=0; x<this.width; x+=50) { ctx.beginPath(); ctx.moveTo(x,0); ctx.lineTo(x,this.height); ctx.stroke(); }
        for(let y=0; y<this.height; y+=50) { ctx.beginPath(); ctx.moveTo(0,y); ctx.lineTo(this.width,y); ctx.stroke(); }
        
        ctx.fillStyle = '#4a4a7a';
        for(const w of this.walls) {
            ctx.beginPath();
            ctx.arc(w.x, w.y, 14, 0, Math.PI*2);
            ctx.fill();
            ctx.strokeStyle = '#6a6a9a';
            ctx.lineWidth = 2;
            ctx.stroke();
        }
        
        for(const p of this.points) p.draw(ctx);
        for(const a of this.enemies) a.draw(ctx, vision, trail);
        
        ctx.fillStyle = 'rgba(100,100,140,0.5)';
        ctx.font = '10px monospace';
        ctx.fillText(`Step: ${this.step} | Ep: ${this.episode}`, 12, this.height-12);
    }
}

// ============================================================================
// 7. LOGGER
// ============================================================================

const Logger = {
    _escape: str => String(str).replace(/[&<>"']/g, m => ({'&':'&amp;','<':'&lt;','>':'&gt;','"':'&quot;',"'":'&#039;'}[m])),
    _truncate: (str, max=180) => str.length > max ? str.slice(0,max) + '‚Ä¶' : str,
    
    log(msg, type='info') {
        const safeMsg = Logger._escape(Logger._truncate(msg));
        const safeType = ['info','success','warn','error'].includes(type) ? type : 'info';
        
        const logEl = document.getElementById('eventLog');
        if (!logEl) { console.log(`[${safeType}] ${safeMsg}`); return; }
        
        const entry = document.createElement('div');
        entry.className = `log-entry ${safeType}`;
        entry.textContent = `[${new Date().toLocaleTimeString()}] ${safeMsg}`;
        
        logEl.insertBefore(entry, logEl.firstChild);
        while (logEl.children.length > 60) logEl.removeChild(logEl.lastChild);
        logEl.scrollTop = 0;
    }
};

// ============================================================================
// 8. GAME ENGINE
// ============================================================================

class GameEngine {
    constructor() {
        this.canvas = document.getElementById('gameCanvas');
        this.ctx = this.canvas.getContext('2d');
        this.resize();
        
        this.world = new World(820, 600);
        this.running = false;
        this.lastTime = 0;
        this.fps = 60;
        this.vision = false;
        this.debug = false;
        this.selectedAgent = null;
        
        this.settings = {
            enableTraining: true,
            enableEvolution: true,
            enableSkillEvolution: true,
            enableFighting: true,
            enableVisualization: false,
            learningRate: 0.005,
            hebbianRate: 0.002,
            mutationRate: 0.1,
            skillGrowthRate: 0.04
        };
        
        this._onResize = this._onResize.bind(this);
        this._onClick = this._onClick.bind(this);
        this.setupEvents();
        this.init();
    }
    
    resize() {
        this.canvas.width = this.canvas.parentElement.clientWidth;
        this.canvas.height = this.canvas.parentElement.clientHeight;
    }
    
    _onResize() { this.resize(); }
    
    setupEvents() {
        window.addEventListener('resize', this._onResize);
        this.canvas.addEventListener('click', this._onClick);
        
        document.getElementById('btnStart').onclick = () => this.toggle();
        document.getElementById('btnReset').onclick = () => this.reset();
        document.getElementById('btnSave').onclick = () => this.save();
        document.getElementById('btnLoad').onclick = () => this.load();
        document.getElementById('btnExport').onclick = () => this.exportWeights();
        document.getElementById('btnImport').onclick = () => document.getElementById('fileImport').click();
        document.getElementById('fileImport').onchange = (e) => this.importWeights(e);
        document.getElementById('btnDebug').onclick = () => this.toggleDebug();
        document.getElementById('btnVision').onclick = () => { this.vision = !this.vision; this.updateBtns(); };
        
        const bindSlider = (id, key, displayId) => {
            document.getElementById(id).oninput = (e) => {
                this.settings[key] = parseFloat(e.target.value);
                document.getElementById(displayId).textContent = e.target.value;
                if (this.world.enemies) {
                    this.world.enemies.forEach(a => {
                        if (a.net) { 
                            a.net.lr = this.settings.learningRate; 
                            a.net.hebbianRate = this.settings.hebbianRate; 
                        }
                    });
                }
            };
        };
        bindSlider('learningRate', 'learningRate', 'learningRateValue');
        bindSlider('hebbianRate', 'hebbianRate', 'hebbianRateValue');
        bindSlider('mutationRate', 'mutationRate', 'mutationRateValue');
        bindSlider('skillGrowth', 'skillGrowthRate', 'skillGrowthValue');
        
        const bindToggle = (id, key) => {
            document.getElementById(id).onchange = (e) => {
                this.settings[key] = e.target.checked;
            };
        };
        bindToggle('enableTraining', 'enableTraining');
        bindToggle('enableEvolution', 'enableEvolution');
        bindToggle('enableSkillEvolution', 'enableSkillEvolution');
        bindToggle('enableFighting', 'enableFighting');
        bindToggle('enableVisualization', 'enableVisualization');
    }
    
    _onClick(e) {
        if (!this.debug) return;
        const rect = this.canvas.getBoundingClientRect();
        const scaleX = this.canvas.width / rect.width;
        const scaleY = this.canvas.height / rect.height;
        const x = (e.clientX - rect.left) * scaleX;
        const y = (e.clientY - rect.top) * scaleY;
        
        let nearest = null, minD = 25;
        for(const a of this.world.enemies) {
            const d = Math.hypot(a.x - x, a.y - y);
            if (d < minD) { minD = d; nearest = a; }
        }
        this.selectedAgent = nearest;
        if (nearest) Logger.log(`üîç –í—ã–±—Ä–∞–Ω –∞–≥–µ–Ω—Ç ${nearest.id}`, 'info');
        this.updateDebugPanel();
    }
    
    init() {
        this.world.spawnAgents();
        this.world.enemies.forEach(a => {
            a.net.lr = this.settings.learningRate;
            a.net.hebbianRate = this.settings.hebbianRate;
        });
        this.updateStats();
        Logger.log('üöÄ AI ARENA v2.1.2 DUAL-MEMORY PRO –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞', 'success');
        Logger.log('üîß –í—Å–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –±–∞–≥–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω—ã + –Ω–µ–π—Ä–æ—Å–µ—Ç—å —Ç–µ–ø–µ—Ä—å —Ä–µ–∞–ª—å–Ω–æ —É–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ–≤–µ–¥–µ–Ω–∏–µ–º', 'success');
        Logger.log('üí° –ù–∞–∂–º–∏—Ç–µ Debug + –∫–ª–∏–∫–Ω–∏—Ç–µ –Ω–∞ –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –∏–Ω—Å–ø–µ–∫—Ü–∏–∏', 'info');
    }
    
    toggle() {
        this.running = !this.running;
        const btn = document.getElementById('btnStart');
        btn.textContent = this.running ? '‚è∏ –ü–∞—É–∑–∞' : '‚ñ∂ –°—Ç–∞—Ä—Ç';
        btn.className = this.running ? 'btn-danger' : 'btn-primary';
        Logger.log(this.running ? '‚ñ∂ –°–∏–º—É–ª—è—Ü–∏—è –∑–∞–ø—É—â–µ–Ω–∞' : '‚è∏ –ü–∞—É–∑–∞', 'info');
        if (this.running) { this.lastTime = performance.now(); this.loop(); }
    }
    
    reset() {
        this.running = false;
        document.getElementById('btnStart').textContent = '‚ñ∂ –°—Ç–∞—Ä—Ç';
        document.getElementById('btnStart').className = 'btn-primary';
        this.world = new World(820, 600);
        this.world.spawnAgents();
        this.world.enemies.forEach(a => { 
            a.net.lr = this.settings.learningRate; 
            a.net.hebbianRate = this.settings.hebbianRate; 
        });
        this.episode = 0;
        Logger.log('üîÑ –°–∏–º—É–ª—è—Ü–∏—è —Å–±—Ä–æ—à–µ–Ω–∞', 'warn');
        this.updateStats();
    }
    
    loop() {
        if (!this.running) return;
        
        const now = performance.now();
        const dt = Math.min((now - this.lastTime) / 16.67, 3);
        this.fps = Math.round(1000 / (now - this.lastTime + 0.001));
        this.lastTime = now;
        
        document.getElementById('fpsCounter').textContent = `FPS: ${this.fps}`;
        
        const state = this.world.update(dt);
        this.world.draw(this.ctx, this.vision);
        this.updateStats(state);
        this.updateDebugPanel();
        
        requestAnimationFrame(() => this.loop());
    }
    
    updateStats(state) {
        if (!state) return;
        const { blue, red, pointsLeft, episode } = state;
        
        document.getElementById('blue-health').style.width = `${blue.health*100}%`;
        document.getElementById('red-health').style.width = `${red.health*100}%`;
        document.getElementById('blue-health').className = `health-fill${blue.health<0.3?' low':''}`;
        document.getElementById('red-health').className = `health-fill${red.health<0.3?' low':''}`;
        
        document.getElementById('blue-reward').textContent = blue.cumulativeReward.toFixed(2);
        document.getElementById('red-reward').textContent = red.cumulativeReward.toFixed(2);
        
        const updateMode = (el, mode) => {
            el.innerHTML = `<span class="mode-badge mode-${mode}">${mode.toUpperCase()}</span>`;
        };
        updateMode(document.getElementById('blue-mode'), blue.mode);
        updateMode(document.getElementById('red-mode'), red.mode);
        
        document.getElementById('blue-wins').textContent = blue.wins;
        document.getElementById('red-wins').textContent = red.wins;
        document.getElementById('blue-conf').textContent = blue.predictive.confidence.toFixed(2);
        document.getElementById('red-conf').textContent = red.predictive.confidence.toFixed(2);
        
        const updateSkills = (prefix, agent) => {
            const skills = ['hunting','fleeing','combat','exploring','avoiding'];
            const els = document.getElementById(prefix + '-skills').children;
            for(let i=0; i<skills.length && i<els.length; i++) {
                const fill = els[i].querySelector('.skill-fill');
                if (fill) {
                    fill.style.width = `${(agent.permanent.skills[skills[i]] || 0.5) * 100}%`;
                }
            }
        };
        updateSkills('blue', blue);
        updateSkills('red', red);
        
        document.getElementById('episodeStat').textContent = episode;
        document.getElementById('stepStat').textContent = this.world.step;
        document.getElementById('dotsStat').textContent = pointsLeft;
        document.getElementById('obstaclesStat').textContent = this.world.walls.length;
        
        const avgFit = (blue.cumulativeReward + red.cumulativeReward) / 2;
        const bestFit = Math.max(blue.cumulativeReward, red.cumulativeReward);
        document.getElementById('fitnessStat').textContent = avgFit.toFixed(1);
        document.getElementById('bestFitnessStat').textContent = bestFit.toFixed(1);
        
        document.getElementById('episodeProgress').style.width = `${(episode % 10) * 10}%`;
    }
    
    updateDebugPanel() {
        const panel = document.getElementById('debugPanel');
        panel.classList.toggle('active', this.debug && this.selectedAgent);
        if (!this.debug || !this.selectedAgent) return;
        
        const info = this.selectedAgent.getDebugInfo();
        document.getElementById('dbgMode').textContent = info.mode;
        document.getElementById('dbgTarget').textContent = info.target;
        document.getElementById('dbgSpeed').textContent = info.speed;
        document.getElementById('dbgAggro').textContent = info.aggro;
        document.getElementById('dbgMemory').textContent = info.memory;
        document.getElementById('dbgNeurons').textContent = info.neurons;
        document.getElementById('dbgReward').textContent = info.reward;
        document.getElementById('dbgStuck').textContent = info.stuck;
        document.getElementById('dbgConf').textContent = info.confidence;
        document.getElementById('dbgPredErr').textContent = info.predError;
        document.getElementById('dbgConfBar').style.width = `${(this.selectedAgent.predictive.confidence || 0.5) * 100}%`;
        document.getElementById('dbgConfVal').textContent = info.confidence;
    }
    
    toggleDebug() {
        this.debug = !this.debug;
        document.getElementById('btnDebug').classList.toggle('active', this.debug);
        document.getElementById('debugPanel').classList.toggle('active', this.debug && this.selectedAgent);
        Logger.log(`üîç Debug ${this.debug?'–≤–∫–ª—é—á—ë–Ω':'–≤—ã–∫–ª—é—á–µ–Ω'}`, this.debug?'success':'info');
    }
    
    updateBtns() {
        document.getElementById('btnVision').classList.toggle('active', this.vision);
    }
    
    save() {
        try {
            const data = {
                version: '2.1.2',
                timestamp: Date.now(),
                settings: this.settings,
                world: {
                    episode: this.world.episode,
                    step: this.world.step,
                    points: this.world.points.map(p => ({x:p.x,y:p.y,type:p.type,collected:p.collected})),
                    walls: this.world.walls.map(w => ({x:w.x,y:w.y}))
                },
                agents: this.world.enemies.map(a => a.toJSON())
            };
            localStorage.setItem('aiArenaV212Save', JSON.stringify(data));
            Logger.log('üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ (v2.1.2 Dual-Memory)', 'success');
        } catch(e) { Logger.log(`‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: ${e.message}`, 'error'); }
    }
    
    load() {
        try {
            const raw = localStorage.getItem('aiArenaV212Save');
            if (!raw) { Logger.log('‚ùå –ù–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–π v2.1.2', 'error'); return; }
            const data = JSON.parse(raw);
            if (data.version !== '2.1.2') { Logger.log('‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç—Å—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ v2.1.2', 'warn'); return; }
            
            this.settings = {...this.settings, ...data.settings};
            document.getElementById('learningRate').value = this.settings.learningRate;
            document.getElementById('hebbianRate').value = this.settings.hebbianRate;
            document.getElementById('mutationRate').value = this.settings.mutationRate;
            document.getElementById('skillGrowth').value = this.settings.skillGrowthRate;
            document.getElementById('learningRateValue').textContent = this.settings.learningRate;
            document.getElementById('hebbianRateValue').textContent = this.settings.hebbianRate;
            document.getElementById('mutationRateValue').textContent = this.settings.mutationRate;
            document.getElementById('skillGrowthValue').textContent = this.settings.skillGrowthRate;
            
            this.world.episode = data.world?.episode || 0;
            this.world.step = data.world?.step || 0;
            this.world.points = data.world?.points.map(p => Object.assign(new SmartPoint(p.x,p.y,p.type), {collected:p.collected})) || [];
            this.world.walls = data.world?.walls || [];
            
            this.world.enemies = data.agents?.map((a,i) => Agent.fromJSON(a, i===0?'#00d4ff':'#ff5577')) || [];
            this.world.enemies.forEach(a => { 
                a.net.lr = this.settings.learningRate; 
                a.net.hebbianRate = this.settings.hebbianRate; 
            });
            
            Logger.log('üìÇ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ v2.1.2', 'success');
            this.updateStats({blue:this.world.enemies[0], red:this.world.enemies[1], pointsLeft:this.world.points.filter(p=>!p.collected).length, episode:this.world.episode});
        } catch(e) { Logger.log(`‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: ${e.message}`, 'error'); }
    }
    
    exportWeights() {
        try {
            const data = {
                version: '2.1.2',
                timestamp: Date.now(),
                blue: this.world.enemies[0].toJSON(),
                red: this.world.enemies[1].toJSON()
            };
            const blob = new Blob([JSON.stringify(data)], {type:'application/json'});
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url; a.download = `arena-v2.1.2-agents-${Date.now()}.json`;
            a.click();
            URL.revokeObjectURL(url);
            Logger.log('üì§ –ê–≥–µ–Ω—Ç—ã —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã (–ø–æ–ª–Ω–∞—è –ø–∞–º—è—Ç—å)', 'success');
        } catch(e) { Logger.log(`‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: ${e.message}`, 'error'); }
    }
    
    importWeights(e) {
        const file = e.target.files[0];
        if (!file) return;
        const reader = new FileReader();
        reader.onload = (ev) => {
            try {
                const data = JSON.parse(ev.target.result);
                if (data.version !== '2.1.2') throw new Error('–¢—Ä–µ–±—É–µ—Ç—Å—è —Ñ–æ—Ä–º–∞—Ç v2.1.2');
                this.world.enemies[0] = Agent.fromJSON(data.blue, '#00d4ff');
                this.world.enemies[1] = Agent.fromJSON(data.red, '#ff5577');
                this.world.enemies.forEach(a => { 
                    a.net.lr = this.settings.learningRate; 
                    a.net.hebbianRate = this.settings.hebbianRate; 
                });
                Logger.log('üì• –ê–≥–µ–Ω—Ç—ã –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã (—Å –ø–∞–º—è—Ç—å—é)', 'success');
            } catch(err) { Logger.log(`‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: ${err.message}`, 'error'); }
        };
        reader.readAsText(file);
        e.target.value = '';
    }
}

// ============================================================================
// 9. LAUNCH
// ============================================================================

let game, settings = {};

window.onload = () => {
    game = new GameEngine();
    settings = game.settings;
};

window.onbeforeunload = () => { if (game) game.running = false; };
</script>
</body>
</html>



              <script>
                              // Anti-cancellation: –µ—Å–ª–∏ –≤–µ–∫—Ç–æ—Ä–∞ –ø–æ–≥–∞—Å–∏–ª–∏ ‚Üí —á–∏—Å—Ç—ã–π desired
if (mag < 0.1) { finalDir = desired; }

// Guaranteed minimum velocity
const minSpeed = 0.3;
const actualSpeed = Math.max(speed, minSpeed);

// Anti-stuck failsafe
if (Math.abs(this.vx) < 0.02) this.vx = finalDir.x * minSpeed;

// –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π —Ä–∞–¥–∏—É—Å: 12 ‚Üí 18
if (d < 18) { p.collected = true; reward += p.value; }

// Force collection fallback
const veryNear = world.points.find(p => !p.collected && Utils.dist(this, p) < 10);
if (veryNear) { veryNear.collected = true; reward += veryNear.value; }

// outputs[9]=direction bias X, outputs[10]=direction bias Y, outputs[11]=target priority
if (networkOutputs && networkOutputs.length >= 12) {
    const dirBiasX = Utils.tanh(networkOutputs[9] || 0) * 30;
    const dirBiasY = Utils.tanh(networkOutputs[10] || 0) * 30;
    const priorityMod = (networkOutputs[11] || 0.5) * 2;
    targets.forEach(t => {
        t.x += dirBiasX * priorityMod * 0.15;
        t.y += dirBiasY * priorityMod * 0.15;
    });
}

// Neural network modulates final direction (outputs[12-13])
if (networkOutputs && networkOutputs.length >= 14) {
    const neuralModX = Utils.tanh(networkOutputs[12] || 0) * 0.2;
    const neuralModY = Utils.tanh(networkOutputs[13] || 0) * 0.2;
    finalDir.x = Utils.clamp(finalDir.x + neuralModX, -1, 1);
    finalDir.y = Utils.clamp(finalDir.y + neuralModY, -1, 1);
}

// Pass network outputs to move() for neural modulation
agent.move(decision.target, decision.speed, this.walls, dt, decision.output);


              </script>
                        </body>
                        </html>
